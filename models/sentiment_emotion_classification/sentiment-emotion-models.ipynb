{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "9BDC0Cy2yNJb",
    "TIpMvh7wyQkX",
    "8VpExyBwjjH3",
    "Hbrql1ouAWLW",
    "6mEpxX5F_vsP"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Library"
   ],
   "metadata": {
    "id": "9BDC0Cy2yNJb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import json\n",
    "import swifter\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "!pip install langdetect\n",
    "from langdetect import detect\n",
    "\n",
    "!pip install googletrans\n",
    "from googletrans import Translator\n",
    "\n",
    "!pip install Sastrawi\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Input, Embedding, GlobalAveragePooling1D, Dropout, Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "URsju9ZIxJx3",
    "outputId": "2afff39c-c312-48a8-e2a9-52eebcf16ac0",
    "ExecuteTime": {
     "end_time": "2025-04-22T12:36:42.841337Z",
     "start_time": "2025-04-22T12:36:26.146335Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lemil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lemil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lemil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\lemil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\lemil\\miniconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from langdetect) (1.17.0)\n",
      "Requirement already satisfied: googletrans in c:\\users\\lemil\\miniconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: httpx>=0.27.2 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.12.2)\n",
      "Requirement already satisfied: Sastrawi in c:\\users\\lemil\\miniconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\lemil\\miniconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T13:36:24.728734Z",
     "start_time": "2025-04-20T13:36:15.123761Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install pydantic",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic)\n",
      "  Downloading pydantic_core-2.33.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\lemil\\miniconda3\\lib\\site-packages (from pydantic) (4.12.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 799.2 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 799.2 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 568.6 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 568.6 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 568.6 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 1.0/2.0 MB 585.6 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/2.0 MB 604.7 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/2.0 MB 604.7 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.6/2.0 MB 635.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 635.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 637.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 657.4 kB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, pydantic\n",
      "Successfully installed annotated-types-0.7.0 pydantic-2.11.3 pydantic-core-2.33.1 typing-inspection-0.4.0\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Data"
   ],
   "metadata": {
    "id": "TIpMvh7wyQkX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../../data/main_dataset/dataset_structured.csv')\n",
    "data = df.copy()\n",
    "data.head(20)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eZMons-4yTVp",
    "outputId": "d0a0ac36-6ed7-454b-f93c-86db8c6ccfb1",
    "ExecuteTime": {
     "end_time": "2025-04-20T11:58:10.385336Z",
     "start_time": "2025-04-20T11:58:10.341094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    sentimen  emosi                                             ulasan\n",
       "0   Negative  Anger  bukan menyenangkan malah bikin kesal hp saya r...\n",
       "1   Negative  Anger  kalo ngak niat bikin gamenya bagus hapus aja d...\n",
       "2   Negative  Anger  makin lama, makin gak jelas dri sblum di updat...\n",
       "3   Negative  Anger  semenjak update sangat sangat buruk setiap mai...\n",
       "4   Negative  Anger                                              burik\n",
       "5   Negative  Anger  5 turun ke 1 | narik padang - denpasar ! sudah...\n",
       "6   Negative  Anger  bangkrut sodara.. Udah hapus aja aplikasinya d...\n",
       "7   Negative  Anger  berita hoax kok di up..kenapa gak cek dan rice...\n",
       "8   Negative  Anger  Beritanya bikin hancur dunia Crypto, Market ta...\n",
       "9   Negative  Anger  beritanya ngawur tidak berdasar seakan-akan be...\n",
       "10  Negative  Anger  Gak ada yang on Malahan gak di balas kesal Kec...\n",
       "11  Negative  Anger  Imdonesia mulai sering memberikan berita HOAX ...\n",
       "12  Negative  Anger  indonesia berita masalah papua selalu memojoka...\n",
       "13  Negative  Anger  Indonesia,berita online yg nggak netral,sering...\n",
       "14  Negative  Anger  kumpulan berita FITNAH berbicara agama dan key...\n",
       "15  Negative  Anger   makin gak jelas masa capekÂ² chat poin gak masuk\n",
       "16  Negative  Anger  malah ngurus game yg satunya lagi ..sementara ...\n",
       "17  Negative  Anger                        media KADRUN dan SAMPAH..!!\n",
       "18  Negative  Anger    media sekarang penuh dengan HOAX. PAYAH BENER!!\n",
       "19  Negative  Anger  Msih kurang sempurna..sistem transfernya kuran..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimen</th>\n",
       "      <th>emosi</th>\n",
       "      <th>ulasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>bukan menyenangkan malah bikin kesal hp saya r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>kalo ngak niat bikin gamenya bagus hapus aja d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>makin lama, makin gak jelas dri sblum di updat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>semenjak update sangat sangat buruk setiap mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>burik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>5 turun ke 1 | narik padang - denpasar ! sudah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>bangkrut sodara.. Udah hapus aja aplikasinya d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>berita hoax kok di up..kenapa gak cek dan rice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Beritanya bikin hancur dunia Crypto, Market ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>beritanya ngawur tidak berdasar seakan-akan be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Gak ada yang on Malahan gak di balas kesal Kec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Imdonesia mulai sering memberikan berita HOAX ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>indonesia berita masalah papua selalu memojoka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Indonesia,berita online yg nggak netral,sering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>kumpulan berita FITNAH berbicara agama dan key...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>makin gak jelas masa capekÂ² chat poin gak masuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>malah ngurus game yg satunya lagi ..sementara ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>media KADRUN dan SAMPAH..!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>media sekarang penuh dengan HOAX. PAYAH BENER!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Msih kurang sempurna..sistem transfernya kuran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Text"
   ],
   "metadata": {
    "id": "QD-JsOTXyTcG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Setup awal\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Slang dictionary\n",
    "merged_slang_file = '../../data/slang/merged_slang_dict.json'\n",
    "\n",
    "with open(merged_slang_file, 'r', encoding='utf-8') as f:\n",
    "    slang_dict = json.load(f)\n",
    "\n",
    "print(f\"Jumlah entri dalam slang_dict: {len(slang_dict)}\")\n",
    "\n",
    "# Stopwords dictionary\n",
    "stop_words = {\n",
    "    \"yang\", \"untuk\", \"dan\", \"di\", \"ke\", \"dari\", \"ini\", \"itu\",\n",
    "    \"dengan\", \"atau\", \"tapi\"\n",
    "}\n",
    "\n",
    "# Custom preprocessor\n",
    "class IndoTextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lowercase=True, remove_non_ascii=True, remove_punctuation=True,\n",
    "                 remove_numbers=True, remove_stopwords=True, stemming=True,\n",
    "                 remove_extra_spaces=True):\n",
    "        self.lowercase = lowercase\n",
    "        self.remove_non_ascii = remove_non_ascii\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.remove_numbers = remove_numbers\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.stemming = stemming\n",
    "        self.remove_extra_spaces = remove_extra_spaces\n",
    "\n",
    "    def normalize_slang(self, text):\n",
    "        tokens = text.split()\n",
    "        return ' '.join(slang_dict.get(word, word) for word in tokens)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            return \"\"\n",
    "\n",
    "        if self.lowercase:\n",
    "            text = text.lower()\n",
    "\n",
    "        text = re.sub(r\"http\\\\S+|www\\\\S+|https\\\\S+\", '', text)\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "        if self.remove_non_ascii:\n",
    "            text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "        if self.remove_punctuation:\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        if self.remove_numbers:\n",
    "            text = re.sub(r'\\\\d+', '', text)\n",
    "\n",
    "        text = self.normalize_slang(text)\n",
    "\n",
    "        tokens = text.split()\n",
    "\n",
    "        if self.remove_stopwords:\n",
    "            tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        if self.stemming:\n",
    "            text = ' '.join(tokens)\n",
    "            text = stemmer.stem(text)\n",
    "            tokens = text.split()\n",
    "\n",
    "        cleaned_text = ' '.join(tokens)\n",
    "\n",
    "        if self.remove_extra_spaces:\n",
    "            cleaned_text = re.sub(r'\\\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "        if len(cleaned_text) <= 5 or re.fullmatch(r'(.)\\\\1{2,}', cleaned_text):\n",
    "            return \"\"\n",
    "\n",
    "        return cleaned_text\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.swifter.apply(self.clean_text)\n",
    "\n",
    "# Pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('preprocessing', IndoTextPreprocessor()),\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000))\n",
    "])"
   ],
   "metadata": {
    "id": "WwK6GfFGxX-N",
    "ExecuteTime": {
     "end_time": "2025-04-20T11:58:49.321886Z",
     "start_time": "2025-04-20T11:58:49.298552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah entri dalam slang_dict: 16470\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tfidf_matrix = text_pipeline.fit_transform(data['ulasan'])\n",
    "data['cleaned_ulasan'] = text_pipeline.named_steps['preprocessing'].transform(data['ulasan'])\n",
    "data.to_csv('cleaned_reviews.csv', index=False)\n",
    "joblib.dump(text_pipeline, '../../models_dump/sentiment_emotion_classification_dump/indo_text_pipeline.pkl')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = pd.read_csv('cleaned_reviews.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling"
   ],
   "metadata": {
    "id": "8VpExyBwjjH3"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Load Data and Preprocessed Inputs\n",
    "df = pd.read_csv(\"cleaned_reviews.csv\")\n",
    "df = df.dropna(subset=['cleaned_ulasan', 'emosi', 'sentimen'])\n",
    "df = df[df['cleaned_ulasan'].str.strip() != \"\"]\n",
    "\n",
    "texts = df['cleaned_ulasan'].astype(str).tolist()\n",
    "emosi_labels = df['emosi'].tolist()\n",
    "sentimen_labels = df['sentimen'].tolist()\n",
    "\n",
    "# 2. Encode Labels\n",
    "le_emosi = LabelEncoder()\n",
    "y_emosi = le_emosi.fit_transform(emosi_labels)\n",
    "num_emosi_classes = len(le_emosi.classes_)\n",
    "\n",
    "le_sentimen = LabelEncoder()\n",
    "y_sentimen = le_sentimen.fit_transform(sentimen_labels)\n",
    "num_sentimen_classes = len(le_sentimen.classes_)\n",
    "\n",
    "with open('../../models_dump/sentiment_emotion_classification_dump/le_emosi.pkl', 'wb') as f:\n",
    "    pickle.dump(le_emosi, f)\n",
    "with open('../../models_dump/sentiment_emotion_classification_dump/le_sentimen.pkl', 'wb') as f:\n",
    "    pickle.dump(le_sentimen, f)\n",
    "\n",
    "# 3. Tokenize and Pad\n",
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "max_length = 120\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "with open('../../models_dump/sentiment_emotion_classification_dump/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# 4. Train-Test Split\n",
    "X_train, X_val, y_train_emosi, y_val_emosi, y_train_sentimen, y_val_sentimen = train_test_split(\n",
    "    padded_sequences, y_emosi, y_sentimen, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = {'emosi_output': y_train_emosi, 'sentimen_output': y_train_sentimen}\n",
    "y_val = {'emosi_output': y_val_emosi, 'sentimen_output': y_val_sentimen}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NN"
   ],
   "metadata": {
    "id": "3OjWG8pvg7lG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MultiOutputDataset(Sequence):\n",
    "    def __init__(self, X, y, batch_size=128, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.X[batch_indices]\n",
    "        batch_y = {\n",
    "            'emosi_output': np.array(self.y['emosi_output'])[batch_indices],\n",
    "            'sentimen_output': np.array(self.y['sentimen_output'])[batch_indices]\n",
    "        }\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "train_dataset = MultiOutputDataset(X_train, y_train, batch_size=128)\n",
    "val_dataset = MultiOutputDataset(X_val, y_val, batch_size=128)\n",
    "\n",
    "class AccuracyThresholdStop(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold=0.96):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        emosi_acc = logs.get('emosi_output_accuracy')\n",
    "        sentimen_acc = logs.get('sentimen_output_accuracy')\n",
    "        if emosi_acc and sentimen_acc and emosi_acc >= self.threshold and sentimen_acc >= self.threshold:\n",
    "            print(f\"\\n✅ Stopping early at epoch {epoch + 1} as accuracy threshold reached.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "input_layer = Input(shape=(max_length,))\n",
    "x = Embedding(vocab_size, embedding_dim)(input_layer)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "emosi_output = Dense(num_emosi_classes, activation='softmax', name='emosi_output')(x)\n",
    "sentimen_output = Dense(num_sentimen_classes, activation='softmax', name='sentimen_output')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[emosi_output, sentimen_output])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'emosi_output': 'sparse_categorical_crossentropy',\n",
    "        'sentimen_output': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'emosi_output': 'accuracy',\n",
    "        'sentimen_output': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    callbacks=[AccuracyThresholdStop()]\n",
    ")\n",
    "\n",
    "model.save('../../models_dump/sentiment_emotion_classification_dump/nn_multitask_model.h5')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flNGKXNog84p",
    "outputId": "3bcd5e0d-9fe3-46af-9695-7171542288f0",
    "ExecuteTime": {
     "end_time": "2025-04-20T12:57:15.432688Z",
     "start_time": "2025-04-20T12:34:05.140530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemil\\miniconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 92ms/step - emosi_output_accuracy: 0.3178 - emosi_output_loss: 1.5508 - loss: 2.6527 - sentimen_output_accuracy: 0.3512 - sentimen_output_loss: 1.1010 - val_emosi_output_accuracy: 0.4014 - val_emosi_output_loss: 1.3265 - val_loss: 2.2448 - val_sentimen_output_accuracy: 0.5652 - val_sentimen_output_loss: 0.9172\n",
      "Epoch 2/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 85ms/step - emosi_output_accuracy: 0.4174 - emosi_output_loss: 1.3145 - loss: 2.2206 - sentimen_output_accuracy: 0.5621 - sentimen_output_loss: 0.9034 - val_emosi_output_accuracy: 0.4221 - val_emosi_output_loss: 1.2866 - val_loss: 2.1550 - val_sentimen_output_accuracy: 0.5762 - val_sentimen_output_loss: 0.8686\n",
      "Epoch 3/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 89ms/step - emosi_output_accuracy: 0.4561 - emosi_output_loss: 1.2444 - loss: 2.0741 - sentimen_output_accuracy: 0.6092 - sentimen_output_loss: 0.8306 - val_emosi_output_accuracy: 0.5757 - val_emosi_output_loss: 1.1095 - val_loss: 1.8304 - val_sentimen_output_accuracy: 0.7110 - val_sentimen_output_loss: 0.7213\n",
      "Epoch 4/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 93ms/step - emosi_output_accuracy: 0.5645 - emosi_output_loss: 1.0714 - loss: 1.7432 - sentimen_output_accuracy: 0.7274 - sentimen_output_loss: 0.6720 - val_emosi_output_accuracy: 0.4543 - val_emosi_output_loss: 1.1791 - val_loss: 1.9740 - val_sentimen_output_accuracy: 0.6501 - val_sentimen_output_loss: 0.7852\n",
      "Epoch 5/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 90ms/step - emosi_output_accuracy: 0.5813 - emosi_output_loss: 1.0496 - loss: 1.6968 - sentimen_output_accuracy: 0.7406 - sentimen_output_loss: 0.6472 - val_emosi_output_accuracy: 0.5964 - val_emosi_output_loss: 1.0872 - val_loss: 1.8117 - val_sentimen_output_accuracy: 0.6313 - val_sentimen_output_loss: 0.7054\n",
      "Epoch 6/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 89ms/step - emosi_output_accuracy: 0.5810 - emosi_output_loss: 1.0456 - loss: 1.6932 - sentimen_output_accuracy: 0.7199 - sentimen_output_loss: 0.6477 - val_emosi_output_accuracy: 0.5774 - val_emosi_output_loss: 1.0956 - val_loss: 1.8175 - val_sentimen_output_accuracy: 0.7184 - val_sentimen_output_loss: 0.7054\n",
      "Epoch 7/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 92ms/step - emosi_output_accuracy: 0.6096 - emosi_output_loss: 1.0221 - loss: 1.6434 - sentimen_output_accuracy: 0.7614 - sentimen_output_loss: 0.6230 - val_emosi_output_accuracy: 0.5518 - val_emosi_output_loss: 1.1231 - val_loss: 1.8422 - val_sentimen_output_accuracy: 0.6998 - val_sentimen_output_loss: 0.7304\n",
      "Epoch 8/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 90ms/step - emosi_output_accuracy: 0.6132 - emosi_output_loss: 1.0039 - loss: 1.6150 - sentimen_output_accuracy: 0.7612 - sentimen_output_loss: 0.6117 - val_emosi_output_accuracy: 0.6042 - val_emosi_output_loss: 1.0552 - val_loss: 1.7387 - val_sentimen_output_accuracy: 0.7384 - val_sentimen_output_loss: 0.6771\n",
      "Epoch 9/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 90ms/step - emosi_output_accuracy: 0.6480 - emosi_output_loss: 0.9460 - loss: 1.5068 - sentimen_output_accuracy: 0.7902 - sentimen_output_loss: 0.5614 - val_emosi_output_accuracy: 0.6057 - val_emosi_output_loss: 1.1308 - val_loss: 1.8476 - val_sentimen_output_accuracy: 0.7369 - val_sentimen_output_loss: 0.7458\n",
      "Epoch 10/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 91ms/step - emosi_output_accuracy: 0.6490 - emosi_output_loss: 0.9432 - loss: 1.5094 - sentimen_output_accuracy: 0.7844 - sentimen_output_loss: 0.5653 - val_emosi_output_accuracy: 0.5662 - val_emosi_output_loss: 1.1779 - val_loss: 2.0011 - val_sentimen_output_accuracy: 0.7042 - val_sentimen_output_loss: 0.8016\n",
      "Epoch 11/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 90ms/step - emosi_output_accuracy: 0.5467 - emosi_output_loss: 1.0514 - loss: 1.7355 - sentimen_output_accuracy: 0.6776 - sentimen_output_loss: 0.6845 - val_emosi_output_accuracy: 0.5211 - val_emosi_output_loss: 1.1616 - val_loss: 1.9463 - val_sentimen_output_accuracy: 0.6496 - val_sentimen_output_loss: 0.7706\n",
      "Epoch 12/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 98ms/step - emosi_output_accuracy: 0.6110 - emosi_output_loss: 0.9498 - loss: 1.5496 - sentimen_output_accuracy: 0.7303 - sentimen_output_loss: 0.5991 - val_emosi_output_accuracy: 0.5716 - val_emosi_output_loss: 1.1210 - val_loss: 1.8891 - val_sentimen_output_accuracy: 0.6859 - val_sentimen_output_loss: 0.7419\n",
      "Epoch 13/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 103ms/step - emosi_output_accuracy: 0.6566 - emosi_output_loss: 0.8718 - loss: 1.4150 - sentimen_output_accuracy: 0.7625 - sentimen_output_loss: 0.5398 - val_emosi_output_accuracy: 0.5708 - val_emosi_output_loss: 1.1080 - val_loss: 1.8467 - val_sentimen_output_accuracy: 0.6893 - val_sentimen_output_loss: 0.7378\n",
      "Epoch 14/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 109ms/step - emosi_output_accuracy: 0.6760 - emosi_output_loss: 0.8275 - loss: 1.3157 - sentimen_output_accuracy: 0.7962 - sentimen_output_loss: 0.4887 - val_emosi_output_accuracy: 0.5833 - val_emosi_output_loss: 1.1554 - val_loss: 1.8970 - val_sentimen_output_accuracy: 0.7093 - val_sentimen_output_loss: 0.7610\n",
      "Epoch 15/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 105ms/step - emosi_output_accuracy: 0.7125 - emosi_output_loss: 0.7698 - loss: 1.2111 - sentimen_output_accuracy: 0.8258 - sentimen_output_loss: 0.4413 - val_emosi_output_accuracy: 0.6264 - val_emosi_output_loss: 1.1017 - val_loss: 1.7994 - val_sentimen_output_accuracy: 0.7520 - val_sentimen_output_loss: 0.7161\n",
      "Epoch 16/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.7446 - emosi_output_loss: 0.6981 - loss: 1.0849 - sentimen_output_accuracy: 0.8503 - sentimen_output_loss: 0.3865 - val_emosi_output_accuracy: 0.6189 - val_emosi_output_loss: 1.1209 - val_loss: 1.8903 - val_sentimen_output_accuracy: 0.7427 - val_sentimen_output_loss: 0.7376\n",
      "Epoch 17/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 111ms/step - emosi_output_accuracy: 0.7626 - emosi_output_loss: 0.6731 - loss: 1.0450 - sentimen_output_accuracy: 0.8611 - sentimen_output_loss: 0.3724 - val_emosi_output_accuracy: 0.6169 - val_emosi_output_loss: 1.1936 - val_loss: 2.0337 - val_sentimen_output_accuracy: 0.7388 - val_sentimen_output_loss: 0.8080\n",
      "Epoch 18/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 113ms/step - emosi_output_accuracy: 0.7684 - emosi_output_loss: 0.6408 - loss: 0.9848 - sentimen_output_accuracy: 0.8715 - sentimen_output_loss: 0.3427 - val_emosi_output_accuracy: 0.6096 - val_emosi_output_loss: 1.2360 - val_loss: 2.0163 - val_sentimen_output_accuracy: 0.7420 - val_sentimen_output_loss: 0.7942\n",
      "Epoch 19/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.7798 - emosi_output_loss: 0.6059 - loss: 0.9222 - sentimen_output_accuracy: 0.8827 - sentimen_output_loss: 0.3155 - val_emosi_output_accuracy: 0.6203 - val_emosi_output_loss: 1.2468 - val_loss: 2.1176 - val_sentimen_output_accuracy: 0.7415 - val_sentimen_output_loss: 0.8293\n",
      "Epoch 20/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 105ms/step - emosi_output_accuracy: 0.7871 - emosi_output_loss: 0.5890 - loss: 0.8932 - sentimen_output_accuracy: 0.8860 - sentimen_output_loss: 0.3042 - val_emosi_output_accuracy: 0.6174 - val_emosi_output_loss: 1.2248 - val_loss: 1.9975 - val_sentimen_output_accuracy: 0.7484 - val_sentimen_output_loss: 0.8065\n",
      "Epoch 21/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 111ms/step - emosi_output_accuracy: 0.8017 - emosi_output_loss: 0.5725 - loss: 0.8662 - sentimen_output_accuracy: 0.8965 - sentimen_output_loss: 0.2937 - val_emosi_output_accuracy: 0.6135 - val_emosi_output_loss: 1.3287 - val_loss: 2.2330 - val_sentimen_output_accuracy: 0.7520 - val_sentimen_output_loss: 0.8461\n",
      "Epoch 22/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 112ms/step - emosi_output_accuracy: 0.8010 - emosi_output_loss: 0.5728 - loss: 0.8686 - sentimen_output_accuracy: 0.8921 - sentimen_output_loss: 0.2957 - val_emosi_output_accuracy: 0.6203 - val_emosi_output_loss: 1.3265 - val_loss: 2.2088 - val_sentimen_output_accuracy: 0.7488 - val_sentimen_output_loss: 0.8880\n",
      "Epoch 23/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 115ms/step - emosi_output_accuracy: 0.8138 - emosi_output_loss: 0.5326 - loss: 0.8071 - sentimen_output_accuracy: 0.9033 - sentimen_output_loss: 0.2742 - val_emosi_output_accuracy: 0.6184 - val_emosi_output_loss: 1.4102 - val_loss: 2.4098 - val_sentimen_output_accuracy: 0.7459 - val_sentimen_output_loss: 0.9470\n",
      "Epoch 24/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 112ms/step - emosi_output_accuracy: 0.8288 - emosi_output_loss: 0.5051 - loss: 0.7647 - sentimen_output_accuracy: 0.9095 - sentimen_output_loss: 0.2551 - val_emosi_output_accuracy: 0.6111 - val_emosi_output_loss: 1.3376 - val_loss: 2.2635 - val_sentimen_output_accuracy: 0.7413 - val_sentimen_output_loss: 0.8673\n",
      "Epoch 25/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 101ms/step - emosi_output_accuracy: 0.8300 - emosi_output_loss: 0.5105 - loss: 0.7664 - sentimen_output_accuracy: 0.9112 - sentimen_output_loss: 0.2558 - val_emosi_output_accuracy: 0.6128 - val_emosi_output_loss: 1.4498 - val_loss: 2.4170 - val_sentimen_output_accuracy: 0.7476 - val_sentimen_output_loss: 0.9698\n",
      "Epoch 26/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 111ms/step - emosi_output_accuracy: 0.8346 - emosi_output_loss: 0.4988 - loss: 0.7534 - sentimen_output_accuracy: 0.9094 - sentimen_output_loss: 0.2581 - val_emosi_output_accuracy: 0.6125 - val_emosi_output_loss: 1.4898 - val_loss: 2.5189 - val_sentimen_output_accuracy: 0.7366 - val_sentimen_output_loss: 0.9840\n",
      "Epoch 27/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 100ms/step - emosi_output_accuracy: 0.8441 - emosi_output_loss: 0.4725 - loss: 0.7148 - sentimen_output_accuracy: 0.9192 - sentimen_output_loss: 0.2359 - val_emosi_output_accuracy: 0.6055 - val_emosi_output_loss: 1.5002 - val_loss: 2.5165 - val_sentimen_output_accuracy: 0.7318 - val_sentimen_output_loss: 0.9762\n",
      "Epoch 28/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 91ms/step - emosi_output_accuracy: 0.8484 - emosi_output_loss: 0.4591 - loss: 0.6898 - sentimen_output_accuracy: 0.9174 - sentimen_output_loss: 0.2306 - val_emosi_output_accuracy: 0.6074 - val_emosi_output_loss: 1.5683 - val_loss: 2.6076 - val_sentimen_output_accuracy: 0.7342 - val_sentimen_output_loss: 1.0598\n",
      "Epoch 29/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 94ms/step - emosi_output_accuracy: 0.8473 - emosi_output_loss: 0.4548 - loss: 0.6859 - sentimen_output_accuracy: 0.9187 - sentimen_output_loss: 0.2300 - val_emosi_output_accuracy: 0.5969 - val_emosi_output_loss: 1.5643 - val_loss: 2.6244 - val_sentimen_output_accuracy: 0.7296 - val_sentimen_output_loss: 1.0405\n",
      "Epoch 30/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 98ms/step - emosi_output_accuracy: 0.8486 - emosi_output_loss: 0.4513 - loss: 0.6697 - sentimen_output_accuracy: 0.9228 - sentimen_output_loss: 0.2183 - val_emosi_output_accuracy: 0.6081 - val_emosi_output_loss: 1.5335 - val_loss: 2.6113 - val_sentimen_output_accuracy: 0.7384 - val_sentimen_output_loss: 1.0251\n",
      "Epoch 31/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 94ms/step - emosi_output_accuracy: 0.8509 - emosi_output_loss: 0.4398 - loss: 0.6603 - sentimen_output_accuracy: 0.9213 - sentimen_output_loss: 0.2207 - val_emosi_output_accuracy: 0.6067 - val_emosi_output_loss: 1.5719 - val_loss: 2.7050 - val_sentimen_output_accuracy: 0.7376 - val_sentimen_output_loss: 1.0591\n",
      "Epoch 32/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 91ms/step - emosi_output_accuracy: 0.8609 - emosi_output_loss: 0.4227 - loss: 0.6326 - sentimen_output_accuracy: 0.9296 - sentimen_output_loss: 0.2099 - val_emosi_output_accuracy: 0.5938 - val_emosi_output_loss: 1.7527 - val_loss: 2.9298 - val_sentimen_output_accuracy: 0.7301 - val_sentimen_output_loss: 1.1666\n",
      "Epoch 33/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 91ms/step - emosi_output_accuracy: 0.8623 - emosi_output_loss: 0.4173 - loss: 0.6243 - sentimen_output_accuracy: 0.9273 - sentimen_output_loss: 0.2066 - val_emosi_output_accuracy: 0.6050 - val_emosi_output_loss: 1.6639 - val_loss: 2.8649 - val_sentimen_output_accuracy: 0.7354 - val_sentimen_output_loss: 1.1197\n",
      "Epoch 34/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 94ms/step - emosi_output_accuracy: 0.8647 - emosi_output_loss: 0.4046 - loss: 0.6117 - sentimen_output_accuracy: 0.9281 - sentimen_output_loss: 0.2072 - val_emosi_output_accuracy: 0.5962 - val_emosi_output_loss: 1.7701 - val_loss: 2.9605 - val_sentimen_output_accuracy: 0.7286 - val_sentimen_output_loss: 1.2206\n",
      "Epoch 35/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 90ms/step - emosi_output_accuracy: 0.8707 - emosi_output_loss: 0.4071 - loss: 0.6191 - sentimen_output_accuracy: 0.9291 - sentimen_output_loss: 0.2115 - val_emosi_output_accuracy: 0.5925 - val_emosi_output_loss: 1.7544 - val_loss: 2.9960 - val_sentimen_output_accuracy: 0.7203 - val_sentimen_output_loss: 1.1940\n",
      "Epoch 36/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 93ms/step - emosi_output_accuracy: 0.8681 - emosi_output_loss: 0.3987 - loss: 0.6054 - sentimen_output_accuracy: 0.9279 - sentimen_output_loss: 0.2055 - val_emosi_output_accuracy: 0.5981 - val_emosi_output_loss: 1.9261 - val_loss: 3.2687 - val_sentimen_output_accuracy: 0.7264 - val_sentimen_output_loss: 1.2940\n",
      "Epoch 37/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 94ms/step - emosi_output_accuracy: 0.8743 - emosi_output_loss: 0.3779 - loss: 0.5648 - sentimen_output_accuracy: 0.9356 - sentimen_output_loss: 0.1863 - val_emosi_output_accuracy: 0.5999 - val_emosi_output_loss: 2.0151 - val_loss: 3.3211 - val_sentimen_output_accuracy: 0.7249 - val_sentimen_output_loss: 1.3619\n",
      "Epoch 38/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 110ms/step - emosi_output_accuracy: 0.8806 - emosi_output_loss: 0.3747 - loss: 0.5580 - sentimen_output_accuracy: 0.9385 - sentimen_output_loss: 0.1887 - val_emosi_output_accuracy: 0.6001 - val_emosi_output_loss: 2.0086 - val_loss: 3.4114 - val_sentimen_output_accuracy: 0.7362 - val_sentimen_output_loss: 1.3702\n",
      "Epoch 39/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 112ms/step - emosi_output_accuracy: 0.8801 - emosi_output_loss: 0.3728 - loss: 0.5652 - sentimen_output_accuracy: 0.9363 - sentimen_output_loss: 0.1921 - val_emosi_output_accuracy: 0.5981 - val_emosi_output_loss: 1.9302 - val_loss: 3.3021 - val_sentimen_output_accuracy: 0.7342 - val_sentimen_output_loss: 1.3221\n",
      "Epoch 40/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 106ms/step - emosi_output_accuracy: 0.8841 - emosi_output_loss: 0.3653 - loss: 0.5545 - sentimen_output_accuracy: 0.9350 - sentimen_output_loss: 0.1893 - val_emosi_output_accuracy: 0.5933 - val_emosi_output_loss: 2.0237 - val_loss: 3.4542 - val_sentimen_output_accuracy: 0.7291 - val_sentimen_output_loss: 1.3579\n",
      "Epoch 41/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 106ms/step - emosi_output_accuracy: 0.8801 - emosi_output_loss: 0.3666 - loss: 0.5586 - sentimen_output_accuracy: 0.9355 - sentimen_output_loss: 0.1904 - val_emosi_output_accuracy: 0.5952 - val_emosi_output_loss: 1.8422 - val_loss: 3.1706 - val_sentimen_output_accuracy: 0.7245 - val_sentimen_output_loss: 1.2844\n",
      "Epoch 42/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 104ms/step - emosi_output_accuracy: 0.8883 - emosi_output_loss: 0.3492 - loss: 0.5369 - sentimen_output_accuracy: 0.9365 - sentimen_output_loss: 0.1851 - val_emosi_output_accuracy: 0.5969 - val_emosi_output_loss: 2.1716 - val_loss: 3.5306 - val_sentimen_output_accuracy: 0.7323 - val_sentimen_output_loss: 1.4758\n",
      "Epoch 43/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 103ms/step - emosi_output_accuracy: 0.8852 - emosi_output_loss: 0.3472 - loss: 0.5279 - sentimen_output_accuracy: 0.9366 - sentimen_output_loss: 0.1794 - val_emosi_output_accuracy: 0.5916 - val_emosi_output_loss: 2.1059 - val_loss: 3.6354 - val_sentimen_output_accuracy: 0.7198 - val_sentimen_output_loss: 1.4262\n",
      "Epoch 44/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 104ms/step - emosi_output_accuracy: 0.8892 - emosi_output_loss: 0.3380 - loss: 0.5117 - sentimen_output_accuracy: 0.9403 - sentimen_output_loss: 0.1737 - val_emosi_output_accuracy: 0.5928 - val_emosi_output_loss: 2.3339 - val_loss: 3.6372 - val_sentimen_output_accuracy: 0.7235 - val_sentimen_output_loss: 1.6014\n",
      "Epoch 45/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 106ms/step - emosi_output_accuracy: 0.8934 - emosi_output_loss: 0.3276 - loss: 0.4977 - sentimen_output_accuracy: 0.9416 - sentimen_output_loss: 0.1702 - val_emosi_output_accuracy: 0.5899 - val_emosi_output_loss: 2.2725 - val_loss: 3.7893 - val_sentimen_output_accuracy: 0.7164 - val_sentimen_output_loss: 1.5920\n",
      "Epoch 46/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 107ms/step - emosi_output_accuracy: 0.8984 - emosi_output_loss: 0.3131 - loss: 0.4739 - sentimen_output_accuracy: 0.9418 - sentimen_output_loss: 0.1607 - val_emosi_output_accuracy: 0.5808 - val_emosi_output_loss: 2.3259 - val_loss: 3.9751 - val_sentimen_output_accuracy: 0.7154 - val_sentimen_output_loss: 1.5817\n",
      "Epoch 47/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 106ms/step - emosi_output_accuracy: 0.8851 - emosi_output_loss: 0.3446 - loss: 0.5294 - sentimen_output_accuracy: 0.9328 - sentimen_output_loss: 0.1842 - val_emosi_output_accuracy: 0.5967 - val_emosi_output_loss: 2.3712 - val_loss: 3.8934 - val_sentimen_output_accuracy: 0.7235 - val_sentimen_output_loss: 1.6565\n",
      "Epoch 48/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 107ms/step - emosi_output_accuracy: 0.8883 - emosi_output_loss: 0.3398 - loss: 0.5163 - sentimen_output_accuracy: 0.9384 - sentimen_output_loss: 0.1765 - val_emosi_output_accuracy: 0.5996 - val_emosi_output_loss: 2.1134 - val_loss: 3.6014 - val_sentimen_output_accuracy: 0.7288 - val_sentimen_output_loss: 1.4292\n",
      "Epoch 49/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 107ms/step - emosi_output_accuracy: 0.8976 - emosi_output_loss: 0.3143 - loss: 0.4727 - sentimen_output_accuracy: 0.9460 - sentimen_output_loss: 0.1579 - val_emosi_output_accuracy: 0.5860 - val_emosi_output_loss: 2.4639 - val_loss: 4.1363 - val_sentimen_output_accuracy: 0.7188 - val_sentimen_output_loss: 1.7077\n",
      "Epoch 50/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 106ms/step - emosi_output_accuracy: 0.8990 - emosi_output_loss: 0.3071 - loss: 0.4622 - sentimen_output_accuracy: 0.9477 - sentimen_output_loss: 0.1541 - val_emosi_output_accuracy: 0.5935 - val_emosi_output_loss: 2.4222 - val_loss: 4.1723 - val_sentimen_output_accuracy: 0.7230 - val_sentimen_output_loss: 1.6627\n",
      "Epoch 51/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 105ms/step - emosi_output_accuracy: 0.9045 - emosi_output_loss: 0.2884 - loss: 0.4346 - sentimen_output_accuracy: 0.9494 - sentimen_output_loss: 0.1460 - val_emosi_output_accuracy: 0.5921 - val_emosi_output_loss: 2.4893 - val_loss: 4.2401 - val_sentimen_output_accuracy: 0.7208 - val_sentimen_output_loss: 1.6616\n",
      "Epoch 52/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.9014 - emosi_output_loss: 0.2967 - loss: 0.4450 - sentimen_output_accuracy: 0.9482 - sentimen_output_loss: 0.1522 - val_emosi_output_accuracy: 0.5921 - val_emosi_output_loss: 2.6382 - val_loss: 4.4715 - val_sentimen_output_accuracy: 0.7145 - val_sentimen_output_loss: 1.8316\n",
      "Epoch 53/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 109ms/step - emosi_output_accuracy: 0.9105 - emosi_output_loss: 0.2857 - loss: 0.4301 - sentimen_output_accuracy: 0.9519 - sentimen_output_loss: 0.1438 - val_emosi_output_accuracy: 0.5896 - val_emosi_output_loss: 2.3838 - val_loss: 4.0529 - val_sentimen_output_accuracy: 0.7206 - val_sentimen_output_loss: 1.5942\n",
      "Epoch 54/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 106ms/step - emosi_output_accuracy: 0.9105 - emosi_output_loss: 0.2830 - loss: 0.4237 - sentimen_output_accuracy: 0.9512 - sentimen_output_loss: 0.1397 - val_emosi_output_accuracy: 0.5930 - val_emosi_output_loss: 2.6405 - val_loss: 4.4933 - val_sentimen_output_accuracy: 0.7154 - val_sentimen_output_loss: 1.8330\n",
      "Epoch 55/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 107ms/step - emosi_output_accuracy: 0.9131 - emosi_output_loss: 0.2682 - loss: 0.4095 - sentimen_output_accuracy: 0.9515 - sentimen_output_loss: 0.1405 - val_emosi_output_accuracy: 0.5899 - val_emosi_output_loss: 2.9586 - val_loss: 4.7470 - val_sentimen_output_accuracy: 0.7110 - val_sentimen_output_loss: 2.0776\n",
      "Epoch 56/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.9152 - emosi_output_loss: 0.2692 - loss: 0.4050 - sentimen_output_accuracy: 0.9543 - sentimen_output_loss: 0.1370 - val_emosi_output_accuracy: 0.5906 - val_emosi_output_loss: 2.6699 - val_loss: 4.6126 - val_sentimen_output_accuracy: 0.7196 - val_sentimen_output_loss: 1.8265\n",
      "Epoch 57/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 105ms/step - emosi_output_accuracy: 0.9110 - emosi_output_loss: 0.2768 - loss: 0.4167 - sentimen_output_accuracy: 0.9533 - sentimen_output_loss: 0.1389 - val_emosi_output_accuracy: 0.5867 - val_emosi_output_loss: 2.8233 - val_loss: 4.6372 - val_sentimen_output_accuracy: 0.7162 - val_sentimen_output_loss: 1.9585\n",
      "Epoch 58/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 106ms/step - emosi_output_accuracy: 0.9148 - emosi_output_loss: 0.2615 - loss: 0.3970 - sentimen_output_accuracy: 0.9531 - sentimen_output_loss: 0.1347 - val_emosi_output_accuracy: 0.5899 - val_emosi_output_loss: 2.8101 - val_loss: 4.8436 - val_sentimen_output_accuracy: 0.7125 - val_sentimen_output_loss: 1.9827\n",
      "Epoch 59/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 97ms/step - emosi_output_accuracy: 0.9208 - emosi_output_loss: 0.2406 - loss: 0.3668 - sentimen_output_accuracy: 0.9577 - sentimen_output_loss: 0.1240 - val_emosi_output_accuracy: 0.5889 - val_emosi_output_loss: 2.9015 - val_loss: 5.0241 - val_sentimen_output_accuracy: 0.7130 - val_sentimen_output_loss: 2.0234\n",
      "Epoch 60/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 90ms/step - emosi_output_accuracy: 0.9217 - emosi_output_loss: 0.2430 - loss: 0.3696 - sentimen_output_accuracy: 0.9571 - sentimen_output_loss: 0.1262 - val_emosi_output_accuracy: 0.5850 - val_emosi_output_loss: 2.9503 - val_loss: 5.1373 - val_sentimen_output_accuracy: 0.7123 - val_sentimen_output_loss: 2.0509\n",
      "Epoch 61/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 96ms/step - emosi_output_accuracy: 0.9228 - emosi_output_loss: 0.2383 - loss: 0.3579 - sentimen_output_accuracy: 0.9588 - sentimen_output_loss: 0.1239 - val_emosi_output_accuracy: 0.5877 - val_emosi_output_loss: 3.0343 - val_loss: 5.0905 - val_sentimen_output_accuracy: 0.7113 - val_sentimen_output_loss: 2.1025\n",
      "Epoch 62/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 107ms/step - emosi_output_accuracy: 0.9256 - emosi_output_loss: 0.2424 - loss: 0.3695 - sentimen_output_accuracy: 0.9601 - sentimen_output_loss: 0.1271 - val_emosi_output_accuracy: 0.5884 - val_emosi_output_loss: 2.9437 - val_loss: 4.9752 - val_sentimen_output_accuracy: 0.7149 - val_sentimen_output_loss: 2.0277\n",
      "Epoch 63/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.9198 - emosi_output_loss: 0.2465 - loss: 0.3754 - sentimen_output_accuracy: 0.9551 - sentimen_output_loss: 0.1281 - val_emosi_output_accuracy: 0.5899 - val_emosi_output_loss: 2.7362 - val_loss: 4.6844 - val_sentimen_output_accuracy: 0.7164 - val_sentimen_output_loss: 1.8781\n",
      "Epoch 64/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 109ms/step - emosi_output_accuracy: 0.9231 - emosi_output_loss: 0.2437 - loss: 0.3632 - sentimen_output_accuracy: 0.9602 - sentimen_output_loss: 0.1199 - val_emosi_output_accuracy: 0.5901 - val_emosi_output_loss: 2.8558 - val_loss: 4.9149 - val_sentimen_output_accuracy: 0.7191 - val_sentimen_output_loss: 1.9642\n",
      "Epoch 65/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 96ms/step - emosi_output_accuracy: 0.9280 - emosi_output_loss: 0.2263 - loss: 0.3398 - sentimen_output_accuracy: 0.9646 - sentimen_output_loss: 0.1129 - val_emosi_output_accuracy: 0.5906 - val_emosi_output_loss: 2.9944 - val_loss: 5.0224 - val_sentimen_output_accuracy: 0.7152 - val_sentimen_output_loss: 2.0484\n",
      "Epoch 66/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 92ms/step - emosi_output_accuracy: 0.9284 - emosi_output_loss: 0.2270 - loss: 0.3369 - sentimen_output_accuracy: 0.9636 - sentimen_output_loss: 0.1099 - val_emosi_output_accuracy: 0.5757 - val_emosi_output_loss: 3.1264 - val_loss: 5.3516 - val_sentimen_output_accuracy: 0.7047 - val_sentimen_output_loss: 2.1901\n",
      "Epoch 67/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 92ms/step - emosi_output_accuracy: 0.9309 - emosi_output_loss: 0.2162 - loss: 0.3260 - sentimen_output_accuracy: 0.9619 - sentimen_output_loss: 0.1099 - val_emosi_output_accuracy: 0.5881 - val_emosi_output_loss: 3.0098 - val_loss: 5.2251 - val_sentimen_output_accuracy: 0.7162 - val_sentimen_output_loss: 2.1145\n",
      "Epoch 68/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 96ms/step - emosi_output_accuracy: 0.9366 - emosi_output_loss: 0.2096 - loss: 0.3153 - sentimen_output_accuracy: 0.9675 - sentimen_output_loss: 0.1055 - val_emosi_output_accuracy: 0.5903 - val_emosi_output_loss: 3.0145 - val_loss: 4.9986 - val_sentimen_output_accuracy: 0.7193 - val_sentimen_output_loss: 2.0775\n",
      "Epoch 69/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 104ms/step - emosi_output_accuracy: 0.9323 - emosi_output_loss: 0.2083 - loss: 0.3117 - sentimen_output_accuracy: 0.9662 - sentimen_output_loss: 0.1038 - val_emosi_output_accuracy: 0.5884 - val_emosi_output_loss: 3.1690 - val_loss: 5.4477 - val_sentimen_output_accuracy: 0.7096 - val_sentimen_output_loss: 2.2141\n",
      "Epoch 70/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.9341 - emosi_output_loss: 0.2056 - loss: 0.3102 - sentimen_output_accuracy: 0.9659 - sentimen_output_loss: 0.1040 - val_emosi_output_accuracy: 0.5864 - val_emosi_output_loss: 3.2872 - val_loss: 5.5198 - val_sentimen_output_accuracy: 0.7169 - val_sentimen_output_loss: 2.1907\n",
      "Epoch 71/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 104ms/step - emosi_output_accuracy: 0.9374 - emosi_output_loss: 0.2004 - loss: 0.2997 - sentimen_output_accuracy: 0.9675 - sentimen_output_loss: 0.1017 - val_emosi_output_accuracy: 0.5852 - val_emosi_output_loss: 3.2108 - val_loss: 5.4899 - val_sentimen_output_accuracy: 0.7110 - val_sentimen_output_loss: 2.2233\n",
      "Epoch 72/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 99ms/step - emosi_output_accuracy: 0.9392 - emosi_output_loss: 0.1898 - loss: 0.2864 - sentimen_output_accuracy: 0.9669 - sentimen_output_loss: 0.0966 - val_emosi_output_accuracy: 0.5872 - val_emosi_output_loss: 3.2872 - val_loss: 5.4946 - val_sentimen_output_accuracy: 0.7089 - val_sentimen_output_loss: 2.2830\n",
      "Epoch 73/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 104ms/step - emosi_output_accuracy: 0.9369 - emosi_output_loss: 0.1970 - loss: 0.2969 - sentimen_output_accuracy: 0.9665 - sentimen_output_loss: 0.1001 - val_emosi_output_accuracy: 0.5852 - val_emosi_output_loss: 3.5615 - val_loss: 5.7914 - val_sentimen_output_accuracy: 0.7147 - val_sentimen_output_loss: 2.4880\n",
      "Epoch 74/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 105ms/step - emosi_output_accuracy: 0.9398 - emosi_output_loss: 0.1845 - loss: 0.2788 - sentimen_output_accuracy: 0.9673 - sentimen_output_loss: 0.0948 - val_emosi_output_accuracy: 0.5867 - val_emosi_output_loss: 3.6091 - val_loss: 6.0621 - val_sentimen_output_accuracy: 0.7079 - val_sentimen_output_loss: 2.4703\n",
      "Epoch 75/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 96ms/step - emosi_output_accuracy: 0.9428 - emosi_output_loss: 0.1802 - loss: 0.2728 - sentimen_output_accuracy: 0.9685 - sentimen_output_loss: 0.0933 - val_emosi_output_accuracy: 0.5889 - val_emosi_output_loss: 3.4608 - val_loss: 6.0198 - val_sentimen_output_accuracy: 0.7142 - val_sentimen_output_loss: 2.4154\n",
      "Epoch 76/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 90ms/step - emosi_output_accuracy: 0.9371 - emosi_output_loss: 0.2014 - loss: 0.3041 - sentimen_output_accuracy: 0.9656 - sentimen_output_loss: 0.1004 - val_emosi_output_accuracy: 0.5828 - val_emosi_output_loss: 3.2224 - val_loss: 5.4604 - val_sentimen_output_accuracy: 0.7089 - val_sentimen_output_loss: 2.1980\n",
      "Epoch 77/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 103ms/step - emosi_output_accuracy: 0.9353 - emosi_output_loss: 0.1954 - loss: 0.2933 - sentimen_output_accuracy: 0.9659 - sentimen_output_loss: 0.0978 - val_emosi_output_accuracy: 0.5808 - val_emosi_output_loss: 3.2207 - val_loss: 5.5073 - val_sentimen_output_accuracy: 0.7057 - val_sentimen_output_loss: 2.2419\n",
      "Epoch 78/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 103ms/step - emosi_output_accuracy: 0.9438 - emosi_output_loss: 0.1804 - loss: 0.2716 - sentimen_output_accuracy: 0.9700 - sentimen_output_loss: 0.0911 - val_emosi_output_accuracy: 0.5867 - val_emosi_output_loss: 3.3343 - val_loss: 5.8112 - val_sentimen_output_accuracy: 0.7113 - val_sentimen_output_loss: 2.3109\n",
      "Epoch 79/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.9433 - emosi_output_loss: 0.1818 - loss: 0.2697 - sentimen_output_accuracy: 0.9693 - sentimen_output_loss: 0.0896 - val_emosi_output_accuracy: 0.5896 - val_emosi_output_loss: 3.3998 - val_loss: 5.9492 - val_sentimen_output_accuracy: 0.7115 - val_sentimen_output_loss: 2.3767\n",
      "Epoch 80/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 107ms/step - emosi_output_accuracy: 0.9479 - emosi_output_loss: 0.1679 - loss: 0.2564 - sentimen_output_accuracy: 0.9717 - sentimen_output_loss: 0.0874 - val_emosi_output_accuracy: 0.5840 - val_emosi_output_loss: 3.4021 - val_loss: 5.7361 - val_sentimen_output_accuracy: 0.7140 - val_sentimen_output_loss: 2.4149\n",
      "Epoch 81/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 105ms/step - emosi_output_accuracy: 0.9455 - emosi_output_loss: 0.1767 - loss: 0.2571 - sentimen_output_accuracy: 0.9713 - sentimen_output_loss: 0.0871 - val_emosi_output_accuracy: 0.5813 - val_emosi_output_loss: 3.5811 - val_loss: 5.9430 - val_sentimen_output_accuracy: 0.7159 - val_sentimen_output_loss: 2.3555\n",
      "Epoch 82/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 106ms/step - emosi_output_accuracy: 0.9464 - emosi_output_loss: 0.1667 - loss: 0.2464 - sentimen_output_accuracy: 0.9723 - sentimen_output_loss: 0.0800 - val_emosi_output_accuracy: 0.5823 - val_emosi_output_loss: 3.2861 - val_loss: 5.6675 - val_sentimen_output_accuracy: 0.7064 - val_sentimen_output_loss: 2.2529\n",
      "Epoch 83/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.9448 - emosi_output_loss: 0.1727 - loss: 0.2632 - sentimen_output_accuracy: 0.9703 - sentimen_output_loss: 0.0899 - val_emosi_output_accuracy: 0.5777 - val_emosi_output_loss: 3.9839 - val_loss: 6.4859 - val_sentimen_output_accuracy: 0.6986 - val_sentimen_output_loss: 2.7901\n",
      "Epoch 84/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 94ms/step - emosi_output_accuracy: 0.9512 - emosi_output_loss: 0.1551 - loss: 0.2337 - sentimen_output_accuracy: 0.9732 - sentimen_output_loss: 0.0784 - val_emosi_output_accuracy: 0.5867 - val_emosi_output_loss: 3.8716 - val_loss: 6.5195 - val_sentimen_output_accuracy: 0.7137 - val_sentimen_output_loss: 2.7350\n",
      "Epoch 85/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 99ms/step - emosi_output_accuracy: 0.9498 - emosi_output_loss: 0.1568 - loss: 0.2369 - sentimen_output_accuracy: 0.9743 - sentimen_output_loss: 0.0802 - val_emosi_output_accuracy: 0.5852 - val_emosi_output_loss: 3.9471 - val_loss: 6.3736 - val_sentimen_output_accuracy: 0.7050 - val_sentimen_output_loss: 2.7000\n",
      "Epoch 86/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 109ms/step - emosi_output_accuracy: 0.9497 - emosi_output_loss: 0.1578 - loss: 0.2412 - sentimen_output_accuracy: 0.9715 - sentimen_output_loss: 0.0828 - val_emosi_output_accuracy: 0.5791 - val_emosi_output_loss: 3.8853 - val_loss: 6.4379 - val_sentimen_output_accuracy: 0.6996 - val_sentimen_output_loss: 2.6816\n",
      "Epoch 87/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 108ms/step - emosi_output_accuracy: 0.9566 - emosi_output_loss: 0.1424 - loss: 0.2122 - sentimen_output_accuracy: 0.9767 - sentimen_output_loss: 0.0684 - val_emosi_output_accuracy: 0.5860 - val_emosi_output_loss: 3.8500 - val_loss: 6.6469 - val_sentimen_output_accuracy: 0.7076 - val_sentimen_output_loss: 2.7085\n",
      "Epoch 88/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 107ms/step - emosi_output_accuracy: 0.9536 - emosi_output_loss: 0.1451 - loss: 0.2165 - sentimen_output_accuracy: 0.9758 - sentimen_output_loss: 0.0714 - val_emosi_output_accuracy: 0.5908 - val_emosi_output_loss: 3.7946 - val_loss: 6.5478 - val_sentimen_output_accuracy: 0.7123 - val_sentimen_output_loss: 2.7346\n",
      "Epoch 89/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 110ms/step - emosi_output_accuracy: 0.9410 - emosi_output_loss: 0.1866 - loss: 0.2814 - sentimen_output_accuracy: 0.9679 - sentimen_output_loss: 0.0975 - val_emosi_output_accuracy: 0.5772 - val_emosi_output_loss: 3.7827 - val_loss: 6.3434 - val_sentimen_output_accuracy: 0.7020 - val_sentimen_output_loss: 2.6546\n",
      "Epoch 90/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 110ms/step - emosi_output_accuracy: 0.9440 - emosi_output_loss: 0.1763 - loss: 0.2635 - sentimen_output_accuracy: 0.9691 - sentimen_output_loss: 0.0940 - val_emosi_output_accuracy: 0.5777 - val_emosi_output_loss: 3.6343 - val_loss: 6.1387 - val_sentimen_output_accuracy: 0.6942 - val_sentimen_output_loss: 2.5416\n",
      "Epoch 91/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 111ms/step - emosi_output_accuracy: 0.9511 - emosi_output_loss: 0.1514 - loss: 0.2299 - sentimen_output_accuracy: 0.9729 - sentimen_output_loss: 0.0784 - val_emosi_output_accuracy: 0.5903 - val_emosi_output_loss: 3.8294 - val_loss: 6.2714 - val_sentimen_output_accuracy: 0.7064 - val_sentimen_output_loss: 2.7608\n",
      "Epoch 92/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 112ms/step - emosi_output_accuracy: 0.9528 - emosi_output_loss: 0.1446 - loss: 0.2174 - sentimen_output_accuracy: 0.9745 - sentimen_output_loss: 0.0729 - val_emosi_output_accuracy: 0.5789 - val_emosi_output_loss: 3.8015 - val_loss: 6.6296 - val_sentimen_output_accuracy: 0.7010 - val_sentimen_output_loss: 2.6530\n",
      "Epoch 93/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 111ms/step - emosi_output_accuracy: 0.9560 - emosi_output_loss: 0.1354 - loss: 0.2032 - sentimen_output_accuracy: 0.9776 - sentimen_output_loss: 0.0674 - val_emosi_output_accuracy: 0.5835 - val_emosi_output_loss: 4.1573 - val_loss: 6.8143 - val_sentimen_output_accuracy: 0.7062 - val_sentimen_output_loss: 2.9111\n",
      "Epoch 94/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 112ms/step - emosi_output_accuracy: 0.9587 - emosi_output_loss: 0.1294 - loss: 0.1998 - sentimen_output_accuracy: 0.9768 - sentimen_output_loss: 0.0693 - val_emosi_output_accuracy: 0.5896 - val_emosi_output_loss: 4.0922 - val_loss: 7.0458 - val_sentimen_output_accuracy: 0.7098 - val_sentimen_output_loss: 2.9071\n",
      "Epoch 95/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 110ms/step - emosi_output_accuracy: 0.9591 - emosi_output_loss: 0.1237 - loss: 0.1892 - sentimen_output_accuracy: 0.9770 - sentimen_output_loss: 0.0651 - val_emosi_output_accuracy: 0.5860 - val_emosi_output_loss: 4.1570 - val_loss: 7.1030 - val_sentimen_output_accuracy: 0.7042 - val_sentimen_output_loss: 2.9142\n",
      "Epoch 96/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 112ms/step - emosi_output_accuracy: 0.9575 - emosi_output_loss: 0.1327 - loss: 0.2000 - sentimen_output_accuracy: 0.9769 - sentimen_output_loss: 0.0672 - val_emosi_output_accuracy: 0.5857 - val_emosi_output_loss: 4.3434 - val_loss: 7.5034 - val_sentimen_output_accuracy: 0.7103 - val_sentimen_output_loss: 2.9964\n",
      "Epoch 97/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 114ms/step - emosi_output_accuracy: 0.9561 - emosi_output_loss: 0.1344 - loss: 0.2072 - sentimen_output_accuracy: 0.9768 - sentimen_output_loss: 0.0703 - val_emosi_output_accuracy: 0.5833 - val_emosi_output_loss: 4.5708 - val_loss: 7.5599 - val_sentimen_output_accuracy: 0.7079 - val_sentimen_output_loss: 3.2639\n",
      "Epoch 98/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 113ms/step - emosi_output_accuracy: 0.9574 - emosi_output_loss: 0.1282 - loss: 0.1924 - sentimen_output_accuracy: 0.9770 - sentimen_output_loss: 0.0633 - val_emosi_output_accuracy: 0.5835 - val_emosi_output_loss: 4.2085 - val_loss: 6.9757 - val_sentimen_output_accuracy: 0.7069 - val_sentimen_output_loss: 2.9031\n",
      "Epoch 99/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 114ms/step - emosi_output_accuracy: 0.9577 - emosi_output_loss: 0.1344 - loss: 0.2030 - sentimen_output_accuracy: 0.9770 - sentimen_output_loss: 0.0686 - val_emosi_output_accuracy: 0.5911 - val_emosi_output_loss: 3.9082 - val_loss: 6.8264 - val_sentimen_output_accuracy: 0.7113 - val_sentimen_output_loss: 2.7370\n",
      "Epoch 100/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 114ms/step - emosi_output_accuracy: 0.9578 - emosi_output_loss: 0.1314 - loss: 0.1969 - sentimen_output_accuracy: 0.9774 - sentimen_output_loss: 0.0658 - val_emosi_output_accuracy: 0.5864 - val_emosi_output_loss: 3.9978 - val_loss: 6.4558 - val_sentimen_output_accuracy: 0.7128 - val_sentimen_output_loss: 2.8514\n",
      "Epoch 101/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 116ms/step - emosi_output_accuracy: 0.9575 - emosi_output_loss: 0.1353 - loss: 0.2083 - sentimen_output_accuracy: 0.9740 - sentimen_output_loss: 0.0725 - val_emosi_output_accuracy: 0.5903 - val_emosi_output_loss: 3.8767 - val_loss: 6.6569 - val_sentimen_output_accuracy: 0.7076 - val_sentimen_output_loss: 2.7361\n",
      "Epoch 102/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 115ms/step - emosi_output_accuracy: 0.9550 - emosi_output_loss: 0.1429 - loss: 0.2171 - sentimen_output_accuracy: 0.9736 - sentimen_output_loss: 0.0742 - val_emosi_output_accuracy: 0.5852 - val_emosi_output_loss: 4.0603 - val_loss: 7.1140 - val_sentimen_output_accuracy: 0.7113 - val_sentimen_output_loss: 2.8617\n",
      "Epoch 103/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 116ms/step - emosi_output_accuracy: 0.9619 - emosi_output_loss: 0.1166 - loss: 0.1793 - sentimen_output_accuracy: 0.9781 - sentimen_output_loss: 0.0620 - val_emosi_output_accuracy: 0.5752 - val_emosi_output_loss: 4.0411 - val_loss: 6.7887 - val_sentimen_output_accuracy: 0.7050 - val_sentimen_output_loss: 2.8071\n",
      "Epoch 104/200\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 107ms/step - emosi_output_accuracy: 0.9641 - emosi_output_loss: 0.1134 - loss: 0.1718 - sentimen_output_accuracy: 0.9799 - sentimen_output_loss: 0.0589\n",
      "✅ Stopping early at epoch 104 as accuracy threshold reached.\n",
      "\u001B[1m129/129\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 114ms/step - emosi_output_accuracy: 0.9641 - emosi_output_loss: 0.1134 - loss: 0.1719 - sentimen_output_accuracy: 0.9799 - sentimen_output_loss: 0.0589 - val_emosi_output_accuracy: 0.5808 - val_emosi_output_loss: 4.1850 - val_loss: 7.1784 - val_sentimen_output_accuracy: 0.7089 - val_sentimen_output_loss: 2.8557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hybrid Method"
   ],
   "metadata": {
    "id": "Il_SzNBjhnA-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "feature_extractor = Model(inputs=model.input, outputs=model.layers[-3].output)\n",
    "nn_features = feature_extractor.predict(padded_sequences)\n",
    "nn_features = np.array(nn_features)\n",
    "\n",
    "y_multi = np.column_stack((y_emosi, y_sentimen))\n",
    "\n",
    "# Make Non-Negative Features for Naive Bayes\n",
    "nn_features_non_neg = np.maximum(0, nn_features)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OR6j0rChrzc",
    "outputId": "1b4e6684-e76b-4419-d97d-818a69195601",
    "ExecuteTime": {
     "end_time": "2025-04-20T13:00:56.639347Z",
     "start_time": "2025-04-20T13:00:50.858742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m641/641\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 8ms/step\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "svm_param_grid = {\n",
    "    'estimator__C': [0.1, 1, 10],\n",
    "    'estimator__kernel': ['linear', 'rbf'],\n",
    "    'estimator__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "svm_multi = MultiOutputClassifier(svm)\n",
    "svm_grid = GridSearchCV(svm_multi, svm_param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "svm_grid.fit(nn_features, y_multi)\n",
    "\n",
    "joblib.dump(svm_grid.best_estimator_, \"../../models_dump/sentiment_emotion_classification_dump/hybrid_nn_svm_model_tuned.pkl\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hS2mkRRVhxOJ",
    "outputId": "229064e2-9dd7-4037-b097-119264eb5012",
    "ExecuteTime": {
     "end_time": "2025-04-20T13:11:25.178574Z",
     "start_time": "2025-04-20T13:01:07.411875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hybrid_nn_svm_model_tuned.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "nn_features_non_neg = np.maximum(0, nn_features)\n",
    "\n",
    "nb_param_grid = {\n",
    "    'estimator__alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb_multi = MultiOutputClassifier(nb)\n",
    "nb_grid = GridSearchCV(nb_multi, nb_param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "nb_grid.fit(nn_features_non_neg, y_multi)\n",
    "\n",
    "joblib.dump(nb_grid.best_estimator_, \"../../models_dump/sentiment_emotion_classification_dump/hybrid_nn_nb_model_tuned.pkl\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5VcOq8whv_j",
    "outputId": "bf9a52c3-13bb-4c55-dbef-c16775f4563c",
    "ExecuteTime": {
     "end_time": "2025-04-20T13:12:51.815149Z",
     "start_time": "2025-04-20T13:12:51.567997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models_dump/sentiment_emotion_classification_dump/hybrid_nn_nb_model_tuned.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Method"
   ],
   "metadata": {
    "id": "iPvZa0oKhz4a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text_pipeline = joblib.load('../../models_dump/sentiment_emotion_classification_dump/indo_text_pipeline.pkl')\n",
    "tfidf_features = text_pipeline.transform(df['cleaned_ulasan'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPmM4T45l4Mh",
    "outputId": "df75e39c-16a9-4efe-fc0f-72f7f34a1ebf",
    "ExecuteTime": {
     "end_time": "2025-04-20T13:13:26.288421Z",
     "start_time": "2025-04-20T13:13:25.093564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20504 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73aa725deb8b4549b7138016f581bbaf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "svm_param_grid = {\n",
    "    'estimator__C': [0.1, 1, 10],\n",
    "    'estimator__kernel': ['linear', 'rbf'],\n",
    "    'estimator__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "svm_multi = MultiOutputClassifier(svm)\n",
    "svm_grid = GridSearchCV(svm_multi, svm_param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "svm_grid.fit(tfidf_features, y_multi)\n",
    "\n",
    "joblib.dump(svm_grid.best_estimator_, \"../../models_dump/sentiment_emotion_classification_dump/standalone_svm_model_tuned.pkl\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Zd-ljlOh178",
    "outputId": "a0cb7f4d-8710-4111-a6f8-b7a801f409b3",
    "ExecuteTime": {
     "end_time": "2025-04-20T13:31:29.631764Z",
     "start_time": "2025-04-20T13:13:35.988282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models_dump/sentiment_emotion_classification_dump/standalone_svm_model_tuned.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "nb_param_grid = {\n",
    "    'estimator__alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb_multi = MultiOutputClassifier(nb)\n",
    "nb_grid = GridSearchCV(nb_multi, nb_param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "nb_grid.fit(tfidf_features, y_multi)\n",
    "\n",
    "joblib.dump(nb_grid.best_estimator_, \"../../models_dump/sentiment_emotion_classification_dump/standalone_nb_model_tuned.pkl\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Si3Ppgyyh3Nj",
    "outputId": "0d070d0e-d98d-4e08-f8c5-7d1a202d4738",
    "ExecuteTime": {
     "end_time": "2025-04-20T13:31:46.704969Z",
     "start_time": "2025-04-20T13:31:44.300848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models_dump/sentiment_emotion_classification_dump/standalone_nb_model_tuned.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": "# Old (Ga dipake)",
   "metadata": {
    "id": "Hbrql1ouAWLW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Load and Preprocess Data\n",
    "data = pd.read_csv(\"/content/cleaned_reviews (3).csv\")  # Update path as needed\n",
    "df = data.dropna(subset=['cleaned_ulasan', 'emosi', 'sentimen']).reset_index(drop=True)\n",
    "\n",
    "texts = df['cleaned_ulasan'].astype(str).tolist()\n",
    "emosi_labels = df['emosi'].tolist()\n",
    "sentimen_labels = df['sentimen'].tolist()\n",
    "\n",
    "# Label Encoding\n",
    "le_emosi = LabelEncoder()\n",
    "encoded_emosi = le_emosi.fit_transform(emosi_labels)\n",
    "num_emosi_classes = len(le_emosi.classes_)\n",
    "\n",
    "le_sentimen = LabelEncoder()\n",
    "encoded_sentimen = le_sentimen.fit_transform(sentimen_labels)\n",
    "num_sentimen_classes = len(le_sentimen.classes_)\n",
    "\n",
    "# Tokenization\n",
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "max_length = 120\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_val, y_train_emosi, y_val_emosi, y_train_sentimen, y_val_sentimen = train_test_split(\n",
    "    padded_sequences, encoded_emosi, encoded_sentimen, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = {\n",
    "    'emosi_output': y_train_emosi,\n",
    "    'sentimen_output': y_train_sentimen\n",
    "}\n",
    "y_val = {\n",
    "    'emosi_output': y_val_emosi,\n",
    "    'sentimen_output': y_val_sentimen\n",
    "}\n",
    "\n",
    "# 3. Custom Data Generator\n",
    "class MultiOutputDataset(Sequence):\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.X[batch_indices]\n",
    "        batch_y = {\n",
    "            'emosi_output': self.y['emosi_output'][batch_indices],\n",
    "            'sentimen_output': self.y['sentimen_output'][batch_indices],\n",
    "        }\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MultiOutputDataset(X_train, y_train, batch_size=32)\n",
    "val_dataset = MultiOutputDataset(X_val, y_val, batch_size=32)\n",
    "\n",
    "# 4. Build Multi-output Neural Network\n",
    "input_layer = Input(shape=(max_length,))\n",
    "x = Embedding(vocab_size, embedding_dim)(input_layer)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "emosi_output = Dense(num_emosi_classes, activation='softmax', name='emosi_output')(x)\n",
    "sentimen_output = Dense(num_sentimen_classes, activation='softmax', name='sentimen_output')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[emosi_output, sentimen_output])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'emosi_output': 'sparse_categorical_crossentropy',\n",
    "        'sentimen_output': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'emosi_output': 'accuracy',\n",
    "        'sentimen_output': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 5. Early Stopping Based on Accuracy\n",
    "class AccuracyThresholdStop(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold=0.96):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        emosi_acc = logs.get('emosi_output_accuracy')\n",
    "        sentimen_acc = logs.get('sentimen_output_accuracy')\n",
    "        if emosi_acc and sentimen_acc and emosi_acc >= self.threshold and sentimen_acc >= self.threshold:\n",
    "            print(f\"\\n✅ Stopping early at epoch {epoch + 1} as accuracy threshold reached.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=200, verbose=1, callbacks=[AccuracyThresholdStop()])\n",
    "\n",
    "# Save model and encoders\n",
    "model.save('multitask_model.h5')\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "with open('le_emosi.pkl', 'wb') as f:\n",
    "    pickle.dump(le_emosi, f)\n",
    "with open('le_sentimen.pkl', 'wb') as f:\n",
    "    pickle.dump(le_sentimen, f)\n",
    "\n",
    "# 6. Feature Extraction from Neural Network\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.layers[-3].output)\n",
    "features = feature_extractor.predict(padded_sequences)\n",
    "\n",
    "# 7. Train Hybrid Models (NN + SVM, NN + Naive Bayes)\n",
    "y_multi = np.column_stack((encoded_emosi, encoded_sentimen))\n",
    "\n",
    "# SVM Hybrid\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "svm_multi = MultiOutputClassifier(svm)\n",
    "svm_multi.fit(features, y_multi)\n",
    "joblib.dump(svm_multi, \"svm_multi_output_model.pkl\")\n",
    "\n",
    "# Naive Bayes Hybrid (use non-negative features)\n",
    "nb = MultinomialNB()\n",
    "nb_multi = MultiOutputClassifier(nb)\n",
    "nb_multi.fit(np.maximum(0, features), y_multi)\n",
    "joblib.dump(nb_multi, \"nb_multi_output_model.pkl\")\n",
    "\n",
    "print(\"✅ All models saved: NN, NN+SVM, NN+NB with multi-output classification.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzwsXqqMKxCw",
    "outputId": "76ece2cf-77a8-4b43-887a-a9a3ea11e683"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m80s\u001B[0m 145ms/step - emosi_output_accuracy: 0.3320 - emosi_output_loss: 1.5048 - loss: 2.5692 - sentimen_output_accuracy: 0.3939 - sentimen_output_loss: 1.0644 - val_emosi_output_accuracy: 0.4539 - val_emosi_output_loss: 1.2863 - val_loss: 2.1658 - val_sentimen_output_accuracy: 0.5647 - val_sentimen_output_loss: 0.8795\n",
      "Epoch 2/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.4953 - emosi_output_loss: 1.2246 - loss: 2.0410 - sentimen_output_accuracy: 0.6213 - sentimen_output_loss: 0.8164 - val_emosi_output_accuracy: 0.5095 - val_emosi_output_loss: 1.1734 - val_loss: 1.9449 - val_sentimen_output_accuracy: 0.6577 - val_sentimen_output_loss: 0.7715\n",
      "Epoch 3/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.5638 - emosi_output_loss: 1.0935 - loss: 1.7844 - sentimen_output_accuracy: 0.7127 - sentimen_output_loss: 0.6909 - val_emosi_output_accuracy: 0.5757 - val_emosi_output_loss: 1.1084 - val_loss: 1.8292 - val_sentimen_output_accuracy: 0.7117 - val_sentimen_output_loss: 0.7208\n",
      "Epoch 4/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 146ms/step - emosi_output_accuracy: 0.6064 - emosi_output_loss: 0.9857 - loss: 1.5748 - sentimen_output_accuracy: 0.7674 - sentimen_output_loss: 0.5891 - val_emosi_output_accuracy: 0.5579 - val_emosi_output_loss: 1.1524 - val_loss: 1.9168 - val_sentimen_output_accuracy: 0.7119 - val_sentimen_output_loss: 0.7644\n",
      "Epoch 5/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 143ms/step - emosi_output_accuracy: 0.6190 - emosi_output_loss: 0.9597 - loss: 1.5260 - sentimen_output_accuracy: 0.7730 - sentimen_output_loss: 0.5664 - val_emosi_output_accuracy: 0.5947 - val_emosi_output_loss: 1.0772 - val_loss: 1.7746 - val_sentimen_output_accuracy: 0.7280 - val_sentimen_output_loss: 0.6974\n",
      "Epoch 6/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m76s\u001B[0m 148ms/step - emosi_output_accuracy: 0.6778 - emosi_output_loss: 0.8364 - loss: 1.3181 - sentimen_output_accuracy: 0.8159 - sentimen_output_loss: 0.4817 - val_emosi_output_accuracy: 0.6062 - val_emosi_output_loss: 1.0703 - val_loss: 1.7578 - val_sentimen_output_accuracy: 0.7417 - val_sentimen_output_loss: 0.6875\n",
      "Epoch 7/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.7090 - emosi_output_loss: 0.7729 - loss: 1.1950 - sentimen_output_accuracy: 0.8434 - sentimen_output_loss: 0.4221 - val_emosi_output_accuracy: 0.6133 - val_emosi_output_loss: 1.1422 - val_loss: 1.8849 - val_sentimen_output_accuracy: 0.7454 - val_sentimen_output_loss: 0.7427\n",
      "Epoch 8/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.7272 - emosi_output_loss: 0.7191 - loss: 1.0998 - sentimen_output_accuracy: 0.8556 - sentimen_output_loss: 0.3805 - val_emosi_output_accuracy: 0.6003 - val_emosi_output_loss: 1.1711 - val_loss: 1.9484 - val_sentimen_output_accuracy: 0.7322 - val_sentimen_output_loss: 0.7773\n",
      "Epoch 9/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 148ms/step - emosi_output_accuracy: 0.7522 - emosi_output_loss: 0.6819 - loss: 1.0443 - sentimen_output_accuracy: 0.8658 - sentimen_output_loss: 0.3624 - val_emosi_output_accuracy: 0.5986 - val_emosi_output_loss: 1.2502 - val_loss: 2.0977 - val_sentimen_output_accuracy: 0.7202 - val_sentimen_output_loss: 0.8475\n",
      "Epoch 10/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m76s\u001B[0m 148ms/step - emosi_output_accuracy: 0.7530 - emosi_output_loss: 0.6439 - loss: 0.9953 - sentimen_output_accuracy: 0.8591 - sentimen_output_loss: 0.3514 - val_emosi_output_accuracy: 0.6113 - val_emosi_output_loss: 1.2041 - val_loss: 2.0055 - val_sentimen_output_accuracy: 0.7373 - val_sentimen_output_loss: 0.8013\n",
      "Epoch 11/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 145ms/step - emosi_output_accuracy: 0.7902 - emosi_output_loss: 0.5901 - loss: 0.8944 - sentimen_output_accuracy: 0.8919 - sentimen_output_loss: 0.3043 - val_emosi_output_accuracy: 0.6157 - val_emosi_output_loss: 1.2581 - val_loss: 2.0900 - val_sentimen_output_accuracy: 0.7405 - val_sentimen_output_loss: 0.8319\n",
      "Epoch 12/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.8055 - emosi_output_loss: 0.5502 - loss: 0.8332 - sentimen_output_accuracy: 0.8999 - sentimen_output_loss: 0.2829 - val_emosi_output_accuracy: 0.6160 - val_emosi_output_loss: 1.3504 - val_loss: 2.2634 - val_sentimen_output_accuracy: 0.7422 - val_sentimen_output_loss: 0.9130\n",
      "Epoch 13/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 145ms/step - emosi_output_accuracy: 0.8230 - emosi_output_loss: 0.5077 - loss: 0.7583 - sentimen_output_accuracy: 0.9118 - sentimen_output_loss: 0.2506 - val_emosi_output_accuracy: 0.6147 - val_emosi_output_loss: 1.3986 - val_loss: 2.3456 - val_sentimen_output_accuracy: 0.7397 - val_sentimen_output_loss: 0.9470\n",
      "Epoch 14/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 145ms/step - emosi_output_accuracy: 0.8410 - emosi_output_loss: 0.4565 - loss: 0.6767 - sentimen_output_accuracy: 0.9232 - sentimen_output_loss: 0.2202 - val_emosi_output_accuracy: 0.6038 - val_emosi_output_loss: 1.5691 - val_loss: 2.6504 - val_sentimen_output_accuracy: 0.7341 - val_sentimen_output_loss: 1.0813\n",
      "Epoch 15/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 143ms/step - emosi_output_accuracy: 0.8502 - emosi_output_loss: 0.4328 - loss: 0.6405 - sentimen_output_accuracy: 0.9263 - sentimen_output_loss: 0.2076 - val_emosi_output_accuracy: 0.5984 - val_emosi_output_loss: 1.4919 - val_loss: 2.4907 - val_sentimen_output_accuracy: 0.7292 - val_sentimen_output_loss: 0.9989\n",
      "Epoch 16/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 146ms/step - emosi_output_accuracy: 0.8602 - emosi_output_loss: 0.4011 - loss: 0.5900 - sentimen_output_accuracy: 0.9341 - sentimen_output_loss: 0.1889 - val_emosi_output_accuracy: 0.6052 - val_emosi_output_loss: 1.6933 - val_loss: 2.8329 - val_sentimen_output_accuracy: 0.7307 - val_sentimen_output_loss: 1.1396\n",
      "Epoch 17/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 146ms/step - emosi_output_accuracy: 0.8760 - emosi_output_loss: 0.3674 - loss: 0.5363 - sentimen_output_accuracy: 0.9420 - sentimen_output_loss: 0.1689 - val_emosi_output_accuracy: 0.6045 - val_emosi_output_loss: 1.7443 - val_loss: 2.9352 - val_sentimen_output_accuracy: 0.7319 - val_sentimen_output_loss: 1.1909\n",
      "Epoch 18/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 144ms/step - emosi_output_accuracy: 0.8884 - emosi_output_loss: 0.3362 - loss: 0.5022 - sentimen_output_accuracy: 0.9437 - sentimen_output_loss: 0.1659 - val_emosi_output_accuracy: 0.6089 - val_emosi_output_loss: 1.7384 - val_loss: 2.9564 - val_sentimen_output_accuracy: 0.7354 - val_sentimen_output_loss: 1.2180\n",
      "Epoch 19/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m76s\u001B[0m 149ms/step - emosi_output_accuracy: 0.8953 - emosi_output_loss: 0.3144 - loss: 0.4648 - sentimen_output_accuracy: 0.9487 - sentimen_output_loss: 0.1505 - val_emosi_output_accuracy: 0.6074 - val_emosi_output_loss: 1.9727 - val_loss: 3.3349 - val_sentimen_output_accuracy: 0.7229 - val_sentimen_output_loss: 1.3623\n",
      "Epoch 20/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m76s\u001B[0m 148ms/step - emosi_output_accuracy: 0.9040 - emosi_output_loss: 0.3029 - loss: 0.4553 - sentimen_output_accuracy: 0.9463 - sentimen_output_loss: 0.1524 - val_emosi_output_accuracy: 0.6082 - val_emosi_output_loss: 1.9036 - val_loss: 3.2363 - val_sentimen_output_accuracy: 0.7236 - val_sentimen_output_loss: 1.3327\n",
      "Epoch 21/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9088 - emosi_output_loss: 0.2790 - loss: 0.4214 - sentimen_output_accuracy: 0.9522 - sentimen_output_loss: 0.1424 - val_emosi_output_accuracy: 0.6003 - val_emosi_output_loss: 1.9803 - val_loss: 3.3199 - val_sentimen_output_accuracy: 0.7175 - val_sentimen_output_loss: 1.3397\n",
      "Epoch 22/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9096 - emosi_output_loss: 0.2759 - loss: 0.4152 - sentimen_output_accuracy: 0.9509 - sentimen_output_loss: 0.1393 - val_emosi_output_accuracy: 0.5881 - val_emosi_output_loss: 2.1690 - val_loss: 3.6718 - val_sentimen_output_accuracy: 0.7065 - val_sentimen_output_loss: 1.5028\n",
      "Epoch 23/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9200 - emosi_output_loss: 0.2454 - loss: 0.3707 - sentimen_output_accuracy: 0.9560 - sentimen_output_loss: 0.1254 - val_emosi_output_accuracy: 0.6025 - val_emosi_output_loss: 2.1643 - val_loss: 3.7105 - val_sentimen_output_accuracy: 0.7192 - val_sentimen_output_loss: 1.5462\n",
      "Epoch 24/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 146ms/step - emosi_output_accuracy: 0.9270 - emosi_output_loss: 0.2305 - loss: 0.3525 - sentimen_output_accuracy: 0.9602 - sentimen_output_loss: 0.1220 - val_emosi_output_accuracy: 0.6062 - val_emosi_output_loss: 2.0340 - val_loss: 3.4745 - val_sentimen_output_accuracy: 0.7151 - val_sentimen_output_loss: 1.4405\n",
      "Epoch 25/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 143ms/step - emosi_output_accuracy: 0.9262 - emosi_output_loss: 0.2274 - loss: 0.3482 - sentimen_output_accuracy: 0.9583 - sentimen_output_loss: 0.1207 - val_emosi_output_accuracy: 0.6001 - val_emosi_output_loss: 2.2264 - val_loss: 3.7726 - val_sentimen_output_accuracy: 0.7126 - val_sentimen_output_loss: 1.5463\n",
      "Epoch 26/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 146ms/step - emosi_output_accuracy: 0.9271 - emosi_output_loss: 0.2224 - loss: 0.3388 - sentimen_output_accuracy: 0.9593 - sentimen_output_loss: 0.1164 - val_emosi_output_accuracy: 0.5974 - val_emosi_output_loss: 2.4782 - val_loss: 4.2284 - val_sentimen_output_accuracy: 0.7068 - val_sentimen_output_loss: 1.7502\n",
      "Epoch 27/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 146ms/step - emosi_output_accuracy: 0.9272 - emosi_output_loss: 0.2207 - loss: 0.3423 - sentimen_output_accuracy: 0.9566 - sentimen_output_loss: 0.1216 - val_emosi_output_accuracy: 0.6038 - val_emosi_output_loss: 2.2704 - val_loss: 3.8395 - val_sentimen_output_accuracy: 0.7153 - val_sentimen_output_loss: 1.5691\n",
      "Epoch 28/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 143ms/step - emosi_output_accuracy: 0.9373 - emosi_output_loss: 0.1908 - loss: 0.2905 - sentimen_output_accuracy: 0.9647 - sentimen_output_loss: 0.0996 - val_emosi_output_accuracy: 0.5967 - val_emosi_output_loss: 2.4018 - val_loss: 4.0854 - val_sentimen_output_accuracy: 0.7119 - val_sentimen_output_loss: 1.6836\n",
      "Epoch 29/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m84s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9411 - emosi_output_loss: 0.1765 - loss: 0.2716 - sentimen_output_accuracy: 0.9669 - sentimen_output_loss: 0.0951 - val_emosi_output_accuracy: 0.5930 - val_emosi_output_loss: 2.5577 - val_loss: 4.3374 - val_sentimen_output_accuracy: 0.7095 - val_sentimen_output_loss: 1.7797\n",
      "Epoch 30/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9400 - emosi_output_loss: 0.1826 - loss: 0.2842 - sentimen_output_accuracy: 0.9633 - sentimen_output_loss: 0.1016 - val_emosi_output_accuracy: 0.5959 - val_emosi_output_loss: 2.6725 - val_loss: 4.5755 - val_sentimen_output_accuracy: 0.7104 - val_sentimen_output_loss: 1.9031\n",
      "Epoch 31/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 145ms/step - emosi_output_accuracy: 0.9425 - emosi_output_loss: 0.1756 - loss: 0.2744 - sentimen_output_accuracy: 0.9653 - sentimen_output_loss: 0.0989 - val_emosi_output_accuracy: 0.5974 - val_emosi_output_loss: 2.7356 - val_loss: 4.7247 - val_sentimen_output_accuracy: 0.7090 - val_sentimen_output_loss: 1.9891\n",
      "Epoch 32/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9473 - emosi_output_loss: 0.1623 - loss: 0.2562 - sentimen_output_accuracy: 0.9657 - sentimen_output_loss: 0.0940 - val_emosi_output_accuracy: 0.5806 - val_emosi_output_loss: 2.6722 - val_loss: 4.5071 - val_sentimen_output_accuracy: 0.6975 - val_sentimen_output_loss: 1.8350\n",
      "Epoch 33/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m76s\u001B[0m 148ms/step - emosi_output_accuracy: 0.9490 - emosi_output_loss: 0.1545 - loss: 0.2420 - sentimen_output_accuracy: 0.9689 - sentimen_output_loss: 0.0874 - val_emosi_output_accuracy: 0.5977 - val_emosi_output_loss: 2.6933 - val_loss: 4.6275 - val_sentimen_output_accuracy: 0.7126 - val_sentimen_output_loss: 1.9342\n",
      "Epoch 34/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9506 - emosi_output_loss: 0.1475 - loss: 0.2242 - sentimen_output_accuracy: 0.9730 - sentimen_output_loss: 0.0767 - val_emosi_output_accuracy: 0.6055 - val_emosi_output_loss: 2.6796 - val_loss: 4.5703 - val_sentimen_output_accuracy: 0.7148 - val_sentimen_output_loss: 1.8907\n",
      "Epoch 35/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m76s\u001B[0m 148ms/step - emosi_output_accuracy: 0.9510 - emosi_output_loss: 0.1455 - loss: 0.2262 - sentimen_output_accuracy: 0.9697 - sentimen_output_loss: 0.0807 - val_emosi_output_accuracy: 0.5874 - val_emosi_output_loss: 3.0168 - val_loss: 5.1407 - val_sentimen_output_accuracy: 0.7014 - val_sentimen_output_loss: 2.1239\n",
      "Epoch 36/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9516 - emosi_output_loss: 0.1407 - loss: 0.2175 - sentimen_output_accuracy: 0.9713 - sentimen_output_loss: 0.0767 - val_emosi_output_accuracy: 0.5854 - val_emosi_output_loss: 2.7834 - val_loss: 4.7733 - val_sentimen_output_accuracy: 0.7046 - val_sentimen_output_loss: 1.9898\n",
      "Epoch 37/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 147ms/step - emosi_output_accuracy: 0.9541 - emosi_output_loss: 0.1395 - loss: 0.2166 - sentimen_output_accuracy: 0.9714 - sentimen_output_loss: 0.0771 - val_emosi_output_accuracy: 0.5930 - val_emosi_output_loss: 2.9501 - val_loss: 5.0698 - val_sentimen_output_accuracy: 0.7051 - val_sentimen_output_loss: 2.1196\n",
      "Epoch 38/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m83s\u001B[0m 150ms/step - emosi_output_accuracy: 0.9560 - emosi_output_loss: 0.1297 - loss: 0.2022 - sentimen_output_accuracy: 0.9724 - sentimen_output_loss: 0.0725 - val_emosi_output_accuracy: 0.5938 - val_emosi_output_loss: 2.9810 - val_loss: 5.0701 - val_sentimen_output_accuracy: 0.7129 - val_sentimen_output_loss: 2.0891\n",
      "Epoch 39/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m76s\u001B[0m 148ms/step - emosi_output_accuracy: 0.9606 - emosi_output_loss: 0.1178 - loss: 0.1841 - sentimen_output_accuracy: 0.9762 - sentimen_output_loss: 0.0663 - val_emosi_output_accuracy: 0.5901 - val_emosi_output_loss: 3.0978 - val_loss: 5.3279 - val_sentimen_output_accuracy: 0.7063 - val_sentimen_output_loss: 2.2301\n",
      "Epoch 40/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m77s\u001B[0m 149ms/step - emosi_output_accuracy: 0.9584 - emosi_output_loss: 0.1211 - loss: 0.1951 - sentimen_output_accuracy: 0.9730 - sentimen_output_loss: 0.0739 - val_emosi_output_accuracy: 0.6018 - val_emosi_output_loss: 3.0777 - val_loss: 5.2618 - val_sentimen_output_accuracy: 0.7085 - val_sentimen_output_loss: 2.1841\n",
      "Epoch 41/200\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 137ms/step - emosi_output_accuracy: 0.9625 - emosi_output_loss: 0.1086 - loss: 0.1726 - sentimen_output_accuracy: 0.9754 - sentimen_output_loss: 0.0640\n",
      "✅ Stopping early at epoch 41 as accuracy threshold reached.\n",
      "\u001B[1m512/512\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 144ms/step - emosi_output_accuracy: 0.9625 - emosi_output_loss: 0.1086 - loss: 0.1726 - sentimen_output_accuracy: 0.9754 - sentimen_output_loss: 0.0640 - val_emosi_output_accuracy: 0.5967 - val_emosi_output_loss: 3.2013 - val_loss: 5.4562 - val_sentimen_output_accuracy: 0.7097 - val_sentimen_output_loss: 2.2549\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m640/640\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 35ms/step\n",
      "✅ All models saved: NN, NN+SVM, NN+NB with multi-output classification.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Testing (Old - Ga dipake)",
   "metadata": {
    "id": "6mEpxX5F_vsP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import re, string, unicodedata\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Define IndoTextPreprocessor\n",
    "translator = Translator()\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "slang_dict = {\n",
    "    \"gak\": \"tidak\", \"ga\": \"tidak\", \"nggak\": \"tidak\", \"gk\": \"tidak\",\n",
    "    \"aja\": \"saja\", \"kalo\": \"kalau\", \"dgn\": \"dengan\", \"yg\": \"yang\",\n",
    "    \"trs\": \"terus\", \"blm\": \"belum\", \"udh\": \"sudah\"\n",
    "}\n",
    "stop_words = set([\"yang\", \"untuk\", \"dan\", \"di\", \"ke\", \"dari\", \"ini\", \"itu\", \"dengan\", \"atau\", \"tapi\"])\n",
    "\n",
    "class IndoTextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.lowercase = True\n",
    "        self.remove_non_ascii = True\n",
    "        self.remove_punctuation = True\n",
    "        self.remove_numbers = True\n",
    "        self.remove_stopwords = True\n",
    "        self.stemming = True\n",
    "        self.remove_extra_spaces = True\n",
    "\n",
    "    def normalize_slang(self, text):\n",
    "        tokens = text.split()\n",
    "        return ' '.join(slang_dict.get(word, word) for word in tokens)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            return \"\"\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            if lang != \"id\":\n",
    "                text = translator.translate(text, src=lang, dest=\"id\").text\n",
    "        except:\n",
    "            pass\n",
    "        if self.lowercase:\n",
    "            text = text.lower()\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        if self.remove_non_ascii:\n",
    "            text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        if self.remove_punctuation:\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        if self.remove_numbers:\n",
    "            text = re.sub(r'\\d+', '', text)\n",
    "        text = self.normalize_slang(text)\n",
    "        tokens = text.split()\n",
    "        if self.remove_stopwords:\n",
    "            tokens = [word for word in tokens if word not in stop_words]\n",
    "        if self.stemming:\n",
    "            text = ' '.join(tokens)\n",
    "            text = stemmer.stem(text)\n",
    "            tokens = text.split()\n",
    "        cleaned_text = ' '.join(tokens)\n",
    "        if self.remove_extra_spaces:\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "        if len(cleaned_text) <= 5 or re.fullmatch(r'(.)\\1{2,}', cleaned_text):\n",
    "            return \"\"\n",
    "        return cleaned_text\n",
    "\n",
    "    def transform(self, text_series):\n",
    "        return text_series.apply(self.clean_text)\n",
    "\n",
    "# Load Saved Components\n",
    "tokenizer = pickle.load(open(\"tokenizer.pkl\", \"rb\"))\n",
    "le_emosi = pickle.load(open(\"le_emosi.pkl\", \"rb\"))\n",
    "le_sentimen = pickle.load(open(\"le_sentimen.pkl\", \"rb\"))\n",
    "\n",
    "nn_model = tf.keras.models.load_model(\"multitask_model.h5\")\n",
    "svm_multi = joblib.load(\"svm_multi_output_model.pkl\")\n",
    "nb_multi = joblib.load(\"nb_multi_output_model.pkl\")\n",
    "\n",
    "# Extract individual estimators\n",
    "svm_emosi, svm_sentimen = svm_multi.estimators_\n",
    "nb_emosi, nb_sentimen = nb_multi.estimators_\n",
    "\n",
    "# Feature Extractor from NN Shared Layer\n",
    "feature_extractor = tf.keras.Model(inputs=nn_model.input, outputs=nn_model.layers[-3].output)\n",
    "\n",
    "# Final Hybrid Prediction Function (NN → Feature → SVM/NB)\n",
    "def predict_all(raw_text_list, do_preprocessing=True):\n",
    "    df = pd.Series(raw_text_list)\n",
    "\n",
    "    if do_preprocessing:\n",
    "        preprocessor = IndoTextPreprocessor()\n",
    "        cleaned = preprocessor.transform(df).fillna(\"\")\n",
    "        cleaned = cleaned.apply(lambda x: x if x.strip() != \"\" else \"kosong\")\n",
    "    else:\n",
    "        cleaned = df.fillna(\"\")\n",
    "\n",
    "    # Tokenization\n",
    "    sequences = tokenizer.texts_to_sequences(cleaned)\n",
    "    padded = pad_sequences(sequences, maxlen=120, padding='post', truncating='post')\n",
    "\n",
    "    # Feature Extraction\n",
    "    features = feature_extractor.predict(padded, batch_size=32)\n",
    "\n",
    "    # Predictions\n",
    "    features_nb = np.maximum(0, features)  # For Naive Bayes\n",
    "    emosi_preds_svm = svm_emosi.predict(features)\n",
    "    sentimen_preds_svm = svm_sentimen.predict(features)\n",
    "    emosi_preds_nb = nb_emosi.predict(features_nb)\n",
    "    sentimen_preds_nb = nb_sentimen.predict(features_nb)\n",
    "\n",
    "    return {\n",
    "        \"cleaned_texts\": cleaned.tolist(),\n",
    "        \"svm\": {\n",
    "            \"emosi\": le_emosi.inverse_transform(emosi_preds_svm),\n",
    "            \"sentimen\": le_sentimen.inverse_transform(sentimen_preds_svm)\n",
    "        },\n",
    "        \"nb\": {\n",
    "            \"emosi\": le_emosi.inverse_transform(emosi_preds_nb),\n",
    "            \"sentimen\": le_sentimen.inverse_transform(sentimen_preds_nb)\n",
    "        },\n",
    "        \"y_pred_raw\": {\n",
    "            \"svm\": {\"emosi\": emosi_preds_svm, \"sentimen\": sentimen_preds_svm},\n",
    "            \"nb\": {\"emosi\": emosi_preds_nb, \"sentimen\": sentimen_preds_nb}\n",
    "        }\n",
    "    }\n",
    "\n",
    "# === Example Run ===\n",
    "if __name__ == \"__main__\":\n",
    "    raw_texts = [\n",
    "        \"Pelayanan sangat cepat dan ramah!\",\n",
    "        \"Gak suka sama kualitasnya.\",\n",
    "        \"Very disappointing, would not recommend.\"\n",
    "    ]\n",
    "\n",
    "    result = predict_all(raw_texts)\n",
    "\n",
    "    print(\"Cleaned Texts:\", result[\"cleaned_texts\"])\n",
    "    print(\"SVM Emosi:\", result[\"svm\"][\"emosi\"])\n",
    "    print(\"SVM Sentimen:\", result[\"svm\"][\"sentimen\"])\n",
    "    print(\"NB Emosi:\", result[\"nb\"][\"emosi\"])\n",
    "    print(\"NB Sentimen:\", result[\"nb\"][\"sentimen\"])"
   ],
   "metadata": {
    "id": "t8uLjufTklQH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "13734c27-0e8d-4721-a17b-a8372cbe5b64"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "<ipython-input-17-9275324ff0f9>:45: RuntimeWarning: coroutine 'Translator.translate' was never awaited\n",
      "  pass\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 759ms/step\n",
      "Cleaned Texts: ['layan sangat cepat ramah', 'tidak suka sama kualitas', 'very disappointing would not recommend']\n",
      "SVM Emosi: ['Happy' 'Neutral' 'Neutral']\n",
      "SVM Sentimen: ['Positive' 'Neutral' 'Neutral']\n",
      "NB Emosi: ['Happy' 'Sad' 'Neutral']\n",
      "NB Sentimen: ['Positive' 'Neutral' 'Neutral']\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pipeline for API/Testing"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import re, string, unicodedata\n",
    "import chardet\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Text Preprocessing\n",
    "translator = Translator()\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "merged_slang_file = '../../data/slang/merged_slang_dict.json'\n",
    "with open(merged_slang_file, 'r', encoding='utf-8') as f:\n",
    "    slang_dict = json.load(f)\n",
    "print(f\"Jumlah entri dalam slang_dict: {len(slang_dict)}\")\n",
    "\n",
    "stop_words = {\n",
    "    \"yang\", \"untuk\", \"dan\", \"di\", \"ke\", \"dari\", \"ini\", \"itu\",\n",
    "    \"dengan\", \"atau\", \"tapi\"\n",
    "}\n",
    "# stop_words = set(stopwords.words('indonesian'))\n",
    "#Lebih bagus pake ini biar lengkap stopwordsnya (lupa ubah aja ini masih make yg atas)\n",
    "\n",
    "class IndoTextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.lowercase = True\n",
    "        self.remove_non_ascii = True\n",
    "        self.remove_punctuation = True\n",
    "        self.remove_numbers = True\n",
    "        self.remove_stopwords = True\n",
    "        self.stemming = True\n",
    "        self.remove_extra_spaces = True\n",
    "\n",
    "    def normalize_slang(self, text):\n",
    "        tokens = text.split()\n",
    "        return ' '.join(slang_dict.get(word, word) for word in tokens)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            return \"\"\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            if lang != \"id\":\n",
    "                text = translator.translate(text, src=lang, dest=\"id\").text\n",
    "        except:\n",
    "            pass\n",
    "        if self.lowercase:\n",
    "            text = text.lower()\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        if self.remove_non_ascii:\n",
    "            text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        if self.remove_punctuation:\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        if self.remove_numbers:\n",
    "            text = re.sub(r'\\d+', '', text)\n",
    "        text = self.normalize_slang(text)\n",
    "        tokens = text.split()\n",
    "        if self.remove_stopwords:\n",
    "            tokens = [word for word in tokens if word not in stop_words]\n",
    "        if self.stemming:\n",
    "            text = ' '.join(tokens)\n",
    "            text = stemmer.stem(text)\n",
    "            tokens = text.split()\n",
    "        cleaned_text = ' '.join(tokens)\n",
    "        if self.remove_extra_spaces:\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "        if len(cleaned_text) <= 5 or re.fullmatch(r'(.)\\1{2,}', cleaned_text):\n",
    "            return \"\"\n",
    "        return cleaned_text\n",
    "\n",
    "    def transform(self, text_series):\n",
    "        return text_series.apply(self.clean_text)\n",
    "\n",
    "# Load Components\n",
    "try:\n",
    "    tokenizer = pickle.load(open(\"../../models_dump/sentiment_emotion_classification_dump/tokenizer.pkl\", \"rb\"))\n",
    "    le_emosi = pickle.load(open(\"../../models_dump/sentiment_emotion_classification_dump/le_emosi.pkl\", \"rb\"))\n",
    "    le_sentimen = pickle.load(open(\"../../models_dump/sentiment_emotion_classification_dump/le_sentimen.pkl\", \"rb\"))\n",
    "    nn_model = tf.keras.models.load_model(\"../models_dump/sentiment_emotion_classification_dump/nn_multitask_model.h5\")\n",
    "    svm_multi = joblib.load(\"../../models_dump/sentiment_emotion_classification_dump/hybrid_nn_svm_model_tuned.pkl\")\n",
    "    nb_multi = joblib.load(\"../../models_dump/sentiment_emotion_classification_dump/hybrid_nn_nb_model_tuned.pkl\")\n",
    "    svm_basic = joblib.load(\"../../models_dump/sentiment_emotion_classification_dump/standalone_svm_model_tuned.pkl\")\n",
    "    nb_basic = joblib.load(\"../../models_dump/sentiment_emotion_classification_dump/standalone_nb_model_tuned.pkl\")\n",
    "except FileNotFoundError as e:\n",
    "    raise RuntimeError(f\"Model or tokenizer file missing: {e}\")\n",
    "\n",
    "# Extract individual models\n",
    "svm_emosi, svm_sentimen = svm_multi.estimators_\n",
    "nb_emosi, nb_sentimen = nb_multi.estimators_\n",
    "\n",
    "# Feature Extractor\n",
    "feature_extractor = tf.keras.Model(inputs=nn_model.input, outputs=nn_model.layers[-3].output)\n",
    "\n",
    "# Prediction Logic\n",
    "def predict_all(raw_text_list, do_preprocessing=True):\n",
    "    if not isinstance(raw_text_list, list) or not all(isinstance(t, str) for t in raw_text_list):\n",
    "        raise ValueError(\"Input must be a list of strings.\")\n",
    "\n",
    "    df = pd.Series(raw_text_list)\n",
    "\n",
    "    if do_preprocessing:\n",
    "        preprocessor = IndoTextPreprocessor()\n",
    "        cleaned = preprocessor.transform(df).fillna(\"\")\n",
    "        cleaned = cleaned.apply(lambda x: x if x.strip() != \"\" else \"kosong\")\n",
    "    else:\n",
    "        cleaned = df.fillna(\"\")\n",
    "\n",
    "    # ---------- Tokenize and pad ----------\n",
    "    sequences = tokenizer.texts_to_sequences(cleaned)\n",
    "    padded = pad_sequences(sequences, maxlen=120, padding='post', truncating='post')\n",
    "\n",
    "    # ---------- Feature extraction for hybrids ----------\n",
    "    features = feature_extractor.predict(padded, batch_size=32)\n",
    "    features_nb = np.maximum(0, features)\n",
    "\n",
    "    # ---------- Hybrid Models ----------\n",
    "    emosi_preds_svm = svm_emosi.predict(features)\n",
    "    sentimen_preds_svm = svm_sentimen.predict(features)\n",
    "    emosi_preds_nb = nb_emosi.predict(features_nb)\n",
    "    sentimen_preds_nb = nb_sentimen.predict(features_nb)\n",
    "\n",
    "    # ---------- Standalone TF-IDF Models ----------\n",
    "    text_pipeline = joblib.load(\"../../models_dump/sentiment_emotion_classification_dump/indo_text_pipeline.pkl\")\n",
    "    tfidf_features = text_pipeline.transform(cleaned)\n",
    "\n",
    "    standalone_preds_svm = svm_basic.predict(tfidf_features)\n",
    "    standalone_preds_nb = nb_basic.predict(tfidf_features)\n",
    "\n",
    "    emosi_preds_svm_basic = standalone_preds_svm[:, 0]\n",
    "    sentimen_preds_svm_basic = standalone_preds_svm[:, 1]\n",
    "    emosi_preds_nb_basic = standalone_preds_nb[:, 0]\n",
    "    sentimen_preds_nb_basic = standalone_preds_nb[:, 1]\n",
    "\n",
    "    # ---------- NN Only Model ----------\n",
    "    nn_pred_emosi_prob, nn_pred_sentimen_prob = nn_model.predict(padded, batch_size=32)\n",
    "    nn_pred_emosi = np.argmax(nn_pred_emosi_prob, axis=1)\n",
    "    nn_pred_sentimen = np.argmax(nn_pred_sentimen_prob, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"cleaned_texts\": cleaned.tolist(),\n",
    "\n",
    "        \"hybrid\": {\n",
    "            \"svm\": {\n",
    "                \"emosi\": le_emosi.inverse_transform(emosi_preds_svm).tolist(),\n",
    "                \"sentimen\": le_sentimen.inverse_transform(sentimen_preds_svm).tolist()\n",
    "            },\n",
    "            \"nb\": {\n",
    "                \"emosi\": le_emosi.inverse_transform(emosi_preds_nb).tolist(),\n",
    "                \"sentimen\": le_sentimen.inverse_transform(sentimen_preds_nb).tolist()\n",
    "            }\n",
    "        },\n",
    "\n",
    "        \"standalone\": {\n",
    "            \"svm\": {\n",
    "                \"emosi\": le_emosi.inverse_transform(emosi_preds_svm_basic).tolist(),\n",
    "                \"sentimen\": le_sentimen.inverse_transform(sentimen_preds_svm_basic).tolist()\n",
    "            },\n",
    "            \"nb\": {\n",
    "                \"emosi\": le_emosi.inverse_transform(emosi_preds_nb_basic).tolist(),\n",
    "                \"sentimen\": le_sentimen.inverse_transform(sentimen_preds_nb_basic).tolist()\n",
    "            }\n",
    "        },\n",
    "\n",
    "        \"nn_only\": {\n",
    "            \"emosi\": le_emosi.inverse_transform(nn_pred_emosi).tolist(),\n",
    "            \"sentimen\": le_sentimen.inverse_transform(nn_pred_sentimen).tolist()\n",
    "        },\n",
    "\n",
    "        \"y_pred_raw\": {\n",
    "            \"hybrid\": {\n",
    "                \"svm\": {\"emosi\": emosi_preds_svm.tolist(), \"sentimen\": sentimen_preds_svm.tolist()},\n",
    "                \"nb\": {\"emosi\": emosi_preds_nb.tolist(), \"sentimen\": sentimen_preds_nb.tolist()}\n",
    "            },\n",
    "            \"standalone\": {\n",
    "                \"svm\": {\"emosi\": emosi_preds_svm_basic.tolist(), \"sentimen\": sentimen_preds_svm_basic.tolist()},\n",
    "                \"nb\": {\"emosi\": emosi_preds_nb_basic.tolist(), \"sentimen\": sentimen_preds_nb_basic.tolist()}\n",
    "            },\n",
    "            \"nn_only\": {\n",
    "                \"emosi\": nn_pred_emosi.tolist(),\n",
    "                \"sentimen\": nn_pred_sentimen.tolist(),\n",
    "                \"emosi_proba\": nn_pred_emosi_prob.tolist(),\n",
    "                \"sentimen_proba\": nn_pred_sentimen_prob.tolist()\n",
    "            }\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    raw_texts = [\n",
    "        \"Pelayanan sangat cepat dan ramah!\",\n",
    "        \"Gak suka sama kualitasnya.\",\n",
    "        \"Terbaik! Makasih ya 😊\",\n",
    "        \"Harga mahal dan kualitas buruk sekali.\",\n",
    "        \"Jelek bgt, gasuka banget, marah nih\",\n",
    "        \"Cinta banget sama aplikasi ini\",\n",
    "        \"Bantu Info nya, Bagaimana Cara Menggantikan Kartu Yg Terdaftar Jika Hilang, Dengan Kartu Yg Baru.?\"\n",
    "    ]\n",
    "\n",
    "    result = predict_all(raw_texts)\n",
    "\n",
    "    for i in range(len(raw_texts)):\n",
    "        print(f\"\\n📝 Original: {raw_texts[i]}\")\n",
    "        print(f\"🧼 Cleaned:  {result['cleaned_texts'][i]}\")\n",
    "\n",
    "        print(\"🔀 NN Only:\")\n",
    "        print(f\"   Emosi:    {result['nn_only']['emosi'][i]}\")\n",
    "        print(f\"   Sentimen: {result['nn_only']['sentimen'][i]}\")\n",
    "\n",
    "        print(\"🔗 Hybrid (NN+SVM):\")\n",
    "        print(f\"   Emosi:    {result['hybrid']['svm']['emosi'][i]}\")\n",
    "        print(f\"   Sentimen: {result['hybrid']['svm']['sentimen'][i]}\")\n",
    "\n",
    "        print(\"🔗 Hybrid (NN+NB):\")\n",
    "        print(f\"   Emosi:    {result['hybrid']['nb']['emosi'][i]}\")\n",
    "        print(f\"   Sentimen: {result['hybrid']['nb']['sentimen'][i]}\")\n",
    "\n",
    "        print(\"🧠 Standalone SVM (TF-IDF):\")\n",
    "        print(f\"   Emosi:    {result['standalone']['svm']['emosi'][i]}\")\n",
    "        print(f\"   Sentimen: {result['standalone']['svm']['sentimen'][i]}\")\n",
    "\n",
    "        print(\"🧠 Standalone NB (TF-IDF):\")\n",
    "        print(f\"   Emosi:    {result['standalone']['nb']['emosi'][i]}\")\n",
    "        print(f\"   Sentimen: {result['standalone']['nb']['sentimen'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_clean = pd.read_csv(\"../cleaned_reviews.csv\")\n",
    "df_clean.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CAJ4H4XJF05W",
    "outputId": "0bc62d45-53f4-45ad-8abe-01289d31911c",
    "ExecuteTime": {
     "end_time": "2025-04-20T13:44:13.253713Z",
     "start_time": "2025-04-20T13:44:13.166831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   sentimen  emosi                                             ulasan  \\\n",
       "0  Negative  Anger  bukan menyenangkan malah bikin kesal hp saya r...   \n",
       "1  Negative  Anger  kalo ngak niat bikin gamenya bagus hapus aja d...   \n",
       "2  Negative  Anger  makin lama, makin gak jelas dri sblum di updat...   \n",
       "3  Negative  Anger  semenjak update sangat sangat buruk setiap mai...   \n",
       "4  Negative  Anger                                              burik   \n",
       "\n",
       "                                      cleaned_ulasan  \n",
       "0  bukan senang bahkan bikin kesal handphone saya...  \n",
       "1  kalau tidak niat bikin game bagus hapus saja s...  \n",
       "2  makin lama makin tidak jelas belum baru game t...  \n",
       "3  semenjak baru sangat sangat buruk tiap main ba...  \n",
       "4                                                NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimen</th>\n",
       "      <th>emosi</th>\n",
       "      <th>ulasan</th>\n",
       "      <th>cleaned_ulasan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>bukan menyenangkan malah bikin kesal hp saya r...</td>\n",
       "      <td>bukan senang bahkan bikin kesal handphone saya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>kalo ngak niat bikin gamenya bagus hapus aja d...</td>\n",
       "      <td>kalau tidak niat bikin game bagus hapus saja s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>makin lama, makin gak jelas dri sblum di updat...</td>\n",
       "      <td>makin lama makin tidak jelas belum baru game t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>semenjak update sangat sangat buruk setiap mai...</td>\n",
       "      <td>semenjak baru sangat sangat buruk tiap main ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Anger</td>\n",
       "      <td>burik</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1-score\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }\n",
    "\n",
    "def compare_models(y_true_emosi, y_true_sentimen, results):\n",
    "    metrics = {\n",
    "        \"NN-only Emosi\": get_metrics(y_true_emosi, results[\"y_pred_raw\"][\"nn_only\"][\"emosi\"]),\n",
    "        \"NN-only Sentimen\": get_metrics(y_true_sentimen, results[\"y_pred_raw\"][\"nn_only\"][\"sentimen\"]),\n",
    "\n",
    "        \"NN-SVM Emosi\": get_metrics(y_true_emosi, results[\"y_pred_raw\"][\"hybrid\"][\"svm\"][\"emosi\"]),\n",
    "        \"NN-SVM Sentimen\": get_metrics(y_true_sentimen, results[\"y_pred_raw\"][\"hybrid\"][\"svm\"][\"sentimen\"]),\n",
    "\n",
    "        \"NN-NB Emosi\": get_metrics(y_true_emosi, results[\"y_pred_raw\"][\"hybrid\"][\"nb\"][\"emosi\"]),\n",
    "        \"NN-NB Sentimen\": get_metrics(y_true_sentimen, results[\"y_pred_raw\"][\"hybrid\"][\"nb\"][\"sentimen\"]),\n",
    "\n",
    "        \"TFIDF-SVM Emosi\": get_metrics(y_true_emosi, results[\"y_pred_raw\"][\"standalone\"][\"svm\"][\"emosi\"]),\n",
    "        \"TFIDF-SVM Sentimen\": get_metrics(y_true_sentimen, results[\"y_pred_raw\"][\"standalone\"][\"svm\"][\"sentimen\"]),\n",
    "\n",
    "        \"TFIDF-NB Emosi\": get_metrics(y_true_emosi, results[\"y_pred_raw\"][\"standalone\"][\"nb\"][\"emosi\"]),\n",
    "        \"TFIDF-NB Sentimen\": get_metrics(y_true_sentimen, results[\"y_pred_raw\"][\"standalone\"][\"nb\"][\"sentimen\"]),\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics)\n",
    "    print(\"\\n=== 📊 Model Performance Comparison ===\")\n",
    "    return df_metrics.round(4)\n"
   ],
   "metadata": {
    "id": "hiUHueNBDM-e",
    "ExecuteTime": {
     "end_time": "2025-04-20T13:44:16.522580Z",
     "start_time": "2025-04-20T13:44:16.516901Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# Get raw texts from DataFrame\n",
    "raw_texts = df_clean[\"cleaned_ulasan\"].astype(str).tolist()\n",
    "\n",
    "# Get true labels\n",
    "y_true_emosi = df_clean[\"emosi\"].tolist()\n",
    "y_true_sentimen = df_clean[\"sentimen\"].tolist()\n",
    "\n",
    "# Encode true labels to match prediction format\n",
    "y_true_emosi_enc = le_emosi.transform(y_true_emosi)\n",
    "y_true_sentimen_enc = le_sentimen.transform(y_true_sentimen)\n",
    "\n",
    "# Run prediction using all 5 models\n",
    "results = predict_all(raw_texts, do_preprocessing=False)\n",
    "\n",
    "# Compare all model performances\n",
    "df_results = compare_models(y_true_emosi_enc, y_true_sentimen_enc, results)\n",
    "\n",
    "# Display the comparison\n",
    "print(df_results)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeTCJjppMMAg",
    "outputId": "e2216f7a-525f-48f0-ba49-add8738622f2",
    "ExecuteTime": {
     "end_time": "2025-04-20T14:14:33.811063Z",
     "start_time": "2025-04-20T13:44:25.528019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 645 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028E8E4FE2A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 645 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028E8E4FE2A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m661/661\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemil\\AppData\\Local\\Temp\\ipykernel_16388\\1168048426.py:51: RuntimeWarning: coroutine 'Translator.translate' was never awaited\n",
      "  pass\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m661/661\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 13ms/step\n",
      "\n",
      "=== 📊 Model Performance Comparison ===\n",
      "           NN-only Emosi  NN-only Sentimen  NN-SVM Emosi  NN-SVM Sentimen  \\\n",
      "Accuracy          0.8657            0.9047        0.8672           0.9021   \n",
      "Precision         0.8717            0.9061        0.8741           0.9037   \n",
      "Recall            0.8657            0.9047        0.8672           0.9021   \n",
      "F1-score          0.8673            0.9047        0.8687           0.9021   \n",
      "\n",
      "           NN-NB Emosi  NN-NB Sentimen  TFIDF-SVM Emosi  TFIDF-SVM Sentimen  \\\n",
      "Accuracy        0.8529          0.9160           0.8217              0.8530   \n",
      "Precision       0.8652          0.9184           0.8229              0.8539   \n",
      "Recall          0.8529          0.9160           0.8217              0.8530   \n",
      "F1-score        0.8562          0.9165           0.8216              0.8530   \n",
      "\n",
      "           TFIDF-NB Emosi  TFIDF-NB Sentimen  \n",
      "Accuracy           0.7018             0.7596  \n",
      "Precision          0.7183             0.7614  \n",
      "Recall             0.7018             0.7596  \n",
      "F1-score           0.6919             0.7564  \n"
     ]
    }
   ],
   "execution_count": 27
  }
 ]
}
